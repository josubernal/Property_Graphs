{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the databases of the API with the following code. We will be using the oldest version of the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"release_id\": \"2022-05-10\",\n",
      "  \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThese datasets provide a variety of information about research papers taken from a snapshot in time of the Semantic Scholar corpus.\\n\\nThis site is provided by The Allen Institute for Artificial Intelligence (\\u201cAI2\\u201d) as a service to the\\nresearch community. The site is covered by AI2 Terms of Use and Privacy Policy. AI2 does not claim\\nownership of any materials on this site unless specifically identified. AI2 does not exercise editorial\\ncontrol over the contents of this site. AI2 respects the intellectual property rights of others. If\\nyou believe your copyright or trademark is being infringed by something on this site, please follow\\nthe \\\"DMCA Notice\\\" process set out in the Terms of Use (https://allenai.org/terms).\\n\\nSAMPLE DATA ACCESS\\nSample data files can be downloaded with the following UNIX command:\\n\\nfor f in $(curl https://s3-us-west-2.amazonaws.com/ai2-s2ag/samples/MANIFEST.txt)\\n  do curl --create-dirs \\\"https://s3-us-west-2.amazonaws.com/ai2-s2ag/$f\\\" -o $f\\ndone\\n\\nFULL DATA ACCESS\\nDownloading the full data requires an API key, which can be obtained at https://www.semanticscholar.org/product/api#Partner-Form\\nFor access to the full datasets, see https://api.semanticscholar.org/api-docs/datasets.\\n\\nLICENSE and ATTRIBUTION\\n\\nSee the README files for each dataset for information about licensing and attribution.\",\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"name\": \"abstracts\",\n",
      "      \"description\": \"Paper abstract text, where available.\\n100M records in 30 1.8GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"abstracts\\\" dataset provides abstract text for selected papers.\\n\\nSCHEMA\\n - openAccessInfo\\n   - externalIds: IDs of this paper in different catalogs\\n   - license/url/status: open-access information provided by Unpaywall, linked by DOI or PubMed Central ID\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"authors\",\n",
      "      \"description\": \"The core attributes of an author (name, affiliation, paper count, etc.). Authors have an \\\"authorId\\\" field, which can be joined to the \\\"authorId\\\" field of the members of a paper's \\\"authors\\\" field.\\n75M records in 30 100MB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"authors\\\" dataset provides summary information about authors.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Author-Data\\n\\nThis dataset does not contain information about an author's papers.\\nInstead, join with authors.authorId from the \\\"papers\\\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"citations\",\n",
      "      \"description\": \"Instances where the bibliography of one paper (the \\\"citingPaper\\\") mentions another paper (the \\\"citedPaper\\\"), where both papers are identified by the \\\"paperId\\\" field. Citations have attributes of their own, (influential classification, intent classification, and citation context).\\n2.4B records in 30 8.5GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"citations\\\" dataset provides details about one paper's citation of another paper.\\n\\nSCHEMA\\n - isinfluential: true/false if the citation is considered influential. https://www.semanticscholar.org/faq#influential-citations\\n - contexts: Text surrounding the citation in the source paper's body.\\n - intents: Classification of the intent behind the citations. https://www.semanticscholar.org/faq#citation-intent\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\\n@inproceedings{cohan-etal-2019-structural,\\n    title = \\\"Structural Scaffolds for Citation Intent Classification in Scientific Publications\\\",\\n    author = \\\"Cohan, Arman  and\\n      Ammar, Waleed  and\\n      van Zuylen, Madeleine  and\\n      Cady, Field\\\",\\n    booktitle = \\\"NAACL\\\",\\n    year = \\\"2019\\\",\\n    url = \\\"https://aclanthology.org/N19-1361\\\",\\n    doi = \\\"10.18653/v1/N19-1361\\\"\\n}\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"embeddings\",\n",
      "      \"description\": \"A dense vector embedding representing the contents of the paper.\\n120M records in 30 28GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"embeddings\\\" dataset provides embeddings representing a paper's contents in vector form.\\n\\nThe model is based on the SPECTER model available at https://github.com/allenai/specter. However, the embeddings\\nincluded in this dataset are not compatible with the embeddings produced by the pretrained model from that repo.\\n\\nLICENSE\\nThis software is released under the Apache 2.0 license. (https://www.apache.org/licenses/LICENSE-2.0)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{specter2020cohan,\\n  title={{SPECTER: Document-level Representation Learning using Citation-informed Transformers}},\\n  author={Arman Cohan and Sergey Feldman and Iz Beltagy and Doug Downey and Daniel S. Weld},\\n  booktitle={ACL},\\n  year={2020}\\n}\\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"papers\",\n",
      "      \"description\": \"The core attributes of a paper (title, authors, date, etc.).\\n200M records in 30 1.5GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"papers\\\" dataset provides core metadata about papers.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data\\n\\nThis dataset does not contain information about a paper's references or citations.\\nInstead, join with citingPaperId/citedPaperId from the \\\"citations\\\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"s2orc\",\n",
      "      \"description\": \"Full-body paper text parsed from open-access PDFs. Identifies structural elements such as paragraphs, sections, and bibliography entries.\\n35M records in 30 3GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"s2orc\\\" dataset contains parsed full-body text from selected papers.\\n\\nA subset of this data was previously released (in a different format) as S2ORC https://github.com/allenai/s2orc\\n\\nThe body text is parsed from PDF documents using Grobid, documented at https://grobid.readthedocs.io.\\nIts output is converted from XML into a single string with a set of annotation spans.\\n\\nSCHEMA\\n - externalIds: IDs of this paper in different catalogs\\n - content:\\n   - source:\\n\\t   - pdfUrls: URLs to the PDF\\n\\t   - oaInfo: license/url/status information from Unpaywall\\n   - text: Full body text as a single string\\n   - annotations: Annotated spans of the full body text\\n\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\n@inproceedings{lo-wang-2020-s2orc,\\n    title = \\\"{S}2{ORC}: The Semantic Scholar Open Research Corpus\\\",\\n    author = \\\"Lo, Kyle  and Wang, Lucy Lu  and Neumann, Mark  and Kinney, Rodney  and Weld, Daniel\\\",\\n    booktitle = \\\"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\\\",\\n    month = jul,\\n    year = \\\"2020\\\",\\n    address = \\\"Online\\\",\\n    publisher = \\\"Association for Computational Linguistics\\\",\\n    url = \\\"https://www.aclweb.org/anthology/2020.acl-main.447\\\",\\n    doi = \\\"10.18653/v1/2020.acl-main.447\\\",\\n    pages = \\\"4969--4983\\\"\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"tldrs\",\n",
      "      \"description\": \"A short natural-language summary of the contents of a paper.\\n58M records in 30 200MB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"tldrs\\\" dataset provides short natural-language summaries of a paper's content.\\n\\nThe model is based on the SciTLDR model available at https://github.com/allenai/scitldr.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@article{cachola2020tldr,\\n  title={{TLDR}: Extreme Summarization of Scientific Documents},\\n  author={Isabel Cachola and Kyle Lo and Arman Cohan and Daniel S. Weld},\\n  journal={arXiv:2004.15011},\\n  year={2020},\\n}\\n\\n\\n\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://api.semanticscholar.org/datasets/v1/release/\"\n",
    "\n",
    "# Set the release id we will work with the first release\n",
    "release_id = \"2022-05-10\"\n",
    "\n",
    "# Make a request to get datasets available the latest release\n",
    "response = requests.get(base_url + release_id)\n",
    "\n",
    "# Print the response data\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "res=json.loads(response.text)[\"datasets\"]\n",
    "dbs = []\n",
    "for dataset in res:\n",
    "    dbs.append(dataset[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each database is really big and because of that it is divided different downloadable parts. Let's list the first link of each part, click on it to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstracts download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/abstracts/20220513_070629_00025_mtwkq_0b601c4a-dca2-4eab-921b-1c86bcba0147.gz?AWSAccessKeyId=ASIA5BJLZJPWVNY7XWLD&Signature=r1HFl3eQak96%2FK44JPfOnGGzGeY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDCgoibXr5ST1vGQfnJrmu27t9594SFGLfhCNaVKKmLAQIgStx8tL0jrvAV65X%2Bhv9EUe%2BN22%2BSbXHrOeD9ndyPNKgqiAQI6f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDP77e%2BCF1IzerJdhQCrcA1YQJ5wy93xcVwLn3d8rJ2YjydoD4LQI9Crl3DJ6oPnOvGi%2FCV9Jcl3YevvZPfaAZtdKbw92IuX8ngV8lTQ4crLAMAPCadfx223Ydrtpp8LBE%2FwFManY5WI1%2FE8%2BuLhU%2FZdUy%2FS%2F9XknX6Mv8Jh%2B%2Fkr2aAbPrlW3YS8JIJFDgRS%2Bw5f6nob%2F%2BVgQjvIqqY0Ss5qMNgI2ZHeicAvdpIfIfN0mUpVQ055lWDVDaV7Twqc1fcaB2R8vrLB8tCxJs8jeh%2BCDPowTxaURBrBqohTiti%2BTG4ciqNSYEuG%2B%2FUEntQxeLfyNvzg2aawDWE3U7plvBnUnB%2FraRXTLdquDhdggrar1TIDE2ICvEqhepDsuRUdAnGRxbG6yCSrwfETNzy9CLNK6T37n7KTOafLa7HiiLs5zAA%2Fp3aooBqJkAxlFaEPzlgcG6zUtGjYy7v7aZESZh8l4ukOS5zDAu4yuNyXFjkQ%2F1mQe2NLHn6Sq2yA54K9VLFimaTyu%2BlY5JBX7sX5NWB9VYN7Ouu168v7DlLSPOL9xAc0N0YYkGs8j%2B%2B0IBzl539gRjV15eyqBeDqEGUSn8CdGWgftDa8rAnkg%2FvFpEt8%2B2AcOmAh5nDgmCRTdQfVAiYymEfUbQtqXE%2Bo0MI3tmr4GOqUB9amNwpV3fnb6aQXkiccEY49VlQ3C1%2BG4zbdqoQYruA2DXce51XtnjWZ99yRJZVWCrjMjWuWwdoNdlpTeNnEAnEiqijPymVTvLo6D9Q6S4%2FxwmDvREmlBUEiQelvuVK7vSOWxHjQ6PG9qgUD3TuOMXJp9%2Bbm0mfJ4aBiFQICRGYZmHnnOlPDLbJ5vGQYi%2FOCYYFU62Wp0WzxAlmsmRpg1lShuozg3&Expires=1741695152\n",
      "authors download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/authors/20220513_071222_00034_g4b97_046945fe-8bc5-4e7b-8bca-95cc504838e8.gz?AWSAccessKeyId=ASIA5BJLZJPWVCBQOD3F&Signature=FCyiIv1QleY70JXnmnEzFhU%2Bouo%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIHh5qgCgD5RgqpxDmoTbb%2FqB9nQGsfIEBA9CDXi0ZDOOAiEAwyXzLbZWt9e7YiQ73%2BgozjTVzzN60dZ7vhkg3BJJIQUqiAQI6f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDNwQ4esI%2Bjc1LISbcCrcA03ymy571ZVk6a3dQsMhnOxrOTsMah2Fs7lOqhmGmYlFDQzujvIZVPx0%2B0i83JCc91EHoQhVPM5a30SgWK5dkSGj0cTH77e%2ByGb5L5xL1j3Wp3v57DwozNPmvAsbkXkqNGoMj%2B%2FKuE3iP%2BKh%2BIJIrQRVXQMLryrnhzGcXcZMToWl73W%2FUL5Dn9UrHLxr9Mav51UVreo0%2BeG5tOIk1R78Bc57wYnKV6iTx9aoqGNlI7iarRR7YvBJzAXBW5z3GVh341HyKmY2izsBPNJxLqmrgLkZ7FQic7KKnbwA70SY%2BYClepo%2FY3%2FPtIGGQEw%2Ff3SydFeoKSGdzF90s1oP4TNLSO%2FIxOXMyYk27nOFQign5skxfa1RyJkB2udGKULKPCINY4xZY%2BtN1ZMlLQhtHOKMo%2Bopu%2BRK%2Bj5GkBanuHBw2r58%2Fj61EfD4vSxVPly8R1K6X1btuYfYdlo2o%2FNEtrzeAIFYE7R9WYD5DeXklyFEQFbnaBonVYGqic3yA9ZRSQnEJVIcdn5SAj36jQ9KtQDalv62nMwrIrcYSLHsAuU%2BCkYFfKwOMidllBXzTMXYAmzyhaV39al6AIBTvu2cKfnAPhII6z9VOKHDrKb5ChvsV4dexEohjh8bCHkBBzYOMNDomr4GOqUB%2B1csZyQHdnEyJp37Wbjbr%2B6HJdXtfwFpn8jQUBhjHx4E7JohbyDvXe3adwaRTyVoCwXwpMeUXoBRKsMT5QxjbsIA9z5kZoOnSUQT7ziq4k%2BaOZZOoRUK0DE2SQaWhH5ZeyT%2FumbmMlasi6hdgtvw5G%2Bcfbl47k7reU1%2BhvOb%2BxnNWzzjsKWE6uJMmHu5JHhSu6sYCrCdxHfFn%2B7fRgOjRND4lqRO&Expires=1741695153\n",
      "citations download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/citations/20220513_071330_00037_xkiix_00bc87b3-00b5-4912-91e0-2e7ea0a433a0.gz?AWSAccessKeyId=ASIA5BJLZJPW7FCH7LGK&Signature=jeZE5sxkugLchovFDfAzh01mazw%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEK%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIE5XhcN1Fynx2htvpavHQyVI7%2Bauh9a3Af3dv62WjW6UAiEA47%2Fi9D8Vs43CTAKg0nGjNeVCxM%2FZt0VeO2nBNpJT91oqiAQI6P%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDPytI2N9p7IM0kDPDyrcA6j8CwKJxdguqZfYiqI9sK6RWHdb80sgfw60RpA7HFvhoMsRKeXB0L1mBNLdPPDDo9RO08UbrYI%2FVFKbSLYKsCh1mAcd80f33aGq%2BS1IiWZJlJXu%2BpdwnQrV7zg553yB%2FKm3DUDX2wKKGi4Z0cvVgCsKhwV%2FHvQioikv%2F8SXB0mPx4iAlxm7mIsjB%2BbGHjKvUsaDDcOJXpaYjOWhgBvgtZuRp3usEUHwQZtmAW7ve%2BbUdkc%2F4t0unwJjGht%2FlppurXtlST%2BIARhgcNdDkkUZB6kDLYsmx1Qn5jLYI5oB5REk6ePCI0AOMhcIY2H74sfeE7at6oSZCVOXti5m1%2BXMWNecALtwKdMCA722%2B0pcFBKVBADiK032weBto15c0VARAdRarq%2F9Yv1sSR5AZPFkgVCv68DA%2FsxS3Mb4ultmvoiVLft75iYIPAqb369vO%2BGEY7%2BjVADatHEtcRLVF%2B0oLbmIqjmFWrK%2F05IuRMAfkzUyJmYIK3%2F2JskFf8cgHHEWOzuKfLLjaB5uHtBgKFkf0GvzcE0HA68l3qWEBioIr9AeFpWAc%2FqvyN14l0rYiBF3iYFISzJnKHo8AkWEQWzPUK6PeqDoR1KaJQ0kzIQkgKDqWvbVYOUn6If%2B7egWMIK9mr4GOqUB5xTGFnHhnuoMnFRytHyKbAsET0IWECrP5Mdlih3stmHbRAEI2aAGIHbJpsLO%2Fx9EeuVxuWNzNWalx9TaWVQQup8yLKOEEjDzzX4rTBYnsVkcOq3XOrYGrUrAXJENtAouMaTOwDpAPdsUr7NX8T1wq2zR6TdfblgoJaIhbzgo0kWq%2BJs46Mo08CBRk0ShgNxUj1zMbCyYUWMPsRxo5n8N%2BCzbG2ta&Expires=1741695154\n",
      "embeddings download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/embeddings/20220513_073500_00025_jcu4c_08b8baf2-dfe2-4d95-804a-01e951f4b532.gz?AWSAccessKeyId=ASIA5BJLZJPWQLS2BNFP&Signature=cFH2K%2FFYJccx%2BD66FIQtoGiEu9w%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEK%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQD6PxQuk3T1WFnjSIp3iGTaO0wYVZBySYRSzgCYn2oEUwIhAO1Ri3e2Qx00tOezOonbe9zRaqeWZxIvY19iveSxeO18KogECOj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMODk2MTI5Mzg3NTAxIgwKPwgKlMOvrCb%2BgN4q3AO8Y22QpuJ3pByIxTuYbFIwa0GhqCQepmY5np2OBb4iOxKZDdWyDk1ew%2BQ%2B8iD0HEkByYnS1QC%2F4Zn%2B8JnfRay%2FOvlps%2FSE12N1lTe50QhxSm2clUElOISXqBKoMbka2IOPpcAX%2FNQldQc3dKHwBjA9durXi80p6zoZgsmk8tTb0aodwBT8HiWUMBR2lw7m%2FyJdgZXAik5sXRYEusZuztMTKhIInUaond6juQ48xRnp7V%2F25K25IdAxofRgwUBPOdu6%2Fg0xFLh%2BIEj%2FmSl1j2acYkak4lcuDUdnsLfQIG8w7USP%2FjEg1hqdSf1ZF7vvwxDDABvS2rhZmWZ84jmZwdqkbIktq1qL6nMMaNQQM8eE7BOnHPFPJ%2BvPAF0mncrNHE%2Fxbz%2BuKL6f04haJAC9vd7zePWPXO2qlDw5XVBRzVPJBnimS8THNoCcBryu%2F9Qxhce9j2EP50uxZc1ZWFWfa9v1NKTtbP3pgGKHtJhzIte3XdwFGnbK6h451fmySKupv%2BvS1S6P%2Be8l7N8mkmqPgZAlKhswj8i3DC%2F20AF4X4qXL5Hij4Fa7GKsrbbxcpaPxpnEA4%2BkPmWF3qY6NZmGQy1XjZySoMX%2F1iY07VMY041d1ekTRFxP08s6pTx2ZTCn0Zq%2BBjqkASKJkuT%2B%2BB8zZnSrhx%2FFyonlhl0P8bdZdoKb7sEOmK6wEgiaDbuGVfRgvh%2BnSk1SxJsjZH8jZBcL8u9TDqkLtDEMasPifK5sy8e2Aw%2BiaEWh2uTDhUg5SA2aNJnsddowM4mfZTIMRj%2FMm89T%2BF6bqRTV4KR6UfusVw6tqGFwEkP%2B7EWQWtskiz9ZUr7R%2BfHotDYWrCABcbUJq6d%2BZyGeho5%2B45ph&Expires=1741695155\n",
      "papers download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/papers/20220513_070151_00012_4bpee_054cd248-48ad-47d6-b0d9-e4fe4333cc61.gz?AWSAccessKeyId=ASIA5BJLZJPWVCBQOD3F&Signature=2d43b5PLBvhFv9%2B7rMxWpRNCy7Q%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIHh5qgCgD5RgqpxDmoTbb%2FqB9nQGsfIEBA9CDXi0ZDOOAiEAwyXzLbZWt9e7YiQ73%2BgozjTVzzN60dZ7vhkg3BJJIQUqiAQI6f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDNwQ4esI%2Bjc1LISbcCrcA03ymy571ZVk6a3dQsMhnOxrOTsMah2Fs7lOqhmGmYlFDQzujvIZVPx0%2B0i83JCc91EHoQhVPM5a30SgWK5dkSGj0cTH77e%2ByGb5L5xL1j3Wp3v57DwozNPmvAsbkXkqNGoMj%2B%2FKuE3iP%2BKh%2BIJIrQRVXQMLryrnhzGcXcZMToWl73W%2FUL5Dn9UrHLxr9Mav51UVreo0%2BeG5tOIk1R78Bc57wYnKV6iTx9aoqGNlI7iarRR7YvBJzAXBW5z3GVh341HyKmY2izsBPNJxLqmrgLkZ7FQic7KKnbwA70SY%2BYClepo%2FY3%2FPtIGGQEw%2Ff3SydFeoKSGdzF90s1oP4TNLSO%2FIxOXMyYk27nOFQign5skxfa1RyJkB2udGKULKPCINY4xZY%2BtN1ZMlLQhtHOKMo%2Bopu%2BRK%2Bj5GkBanuHBw2r58%2Fj61EfD4vSxVPly8R1K6X1btuYfYdlo2o%2FNEtrzeAIFYE7R9WYD5DeXklyFEQFbnaBonVYGqic3yA9ZRSQnEJVIcdn5SAj36jQ9KtQDalv62nMwrIrcYSLHsAuU%2BCkYFfKwOMidllBXzTMXYAmzyhaV39al6AIBTvu2cKfnAPhII6z9VOKHDrKb5ChvsV4dexEohjh8bCHkBBzYOMNDomr4GOqUB%2B1csZyQHdnEyJp37Wbjbr%2B6HJdXtfwFpn8jQUBhjHx4E7JohbyDvXe3adwaRTyVoCwXwpMeUXoBRKsMT5QxjbsIA9z5kZoOnSUQT7ziq4k%2BaOZZOoRUK0DE2SQaWhH5ZeyT%2FumbmMlasi6hdgtvw5G%2Bcfbl47k7reU1%2BhvOb%2BxnNWzzjsKWE6uJMmHu5JHhSu6sYCrCdxHfFn%2B7fRgOjRND4lqRO&Expires=1741695156\n",
      "s2orc download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/s2orc/20220519_000932_00025_dauyy_04c9ef07-dd83-42f4-b36a-4d3ea06c99b0.gz?AWSAccessKeyId=ASIA5BJLZJPWUU7NGIHQ&Signature=XtxIZh60Q1XWGX8X2Fk2ByNiLH8%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCAsVIziRwvTxtYZyF8MxOdkXANJvnLmi2ORNwFPFZTtgIhAM%2BdQ7LAW7FR7VUvLorg9njXQ65T1TCQcIHhiay0kE2gKogECOv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMODk2MTI5Mzg3NTAxIgyIJAVRFQleVye%2Bt5Mq3AP1S55i2Qvw2ub65STygyS%2BOrN4zeTc%2BKPJ09iphIzz7Ud8fj22HbLQj9itG1SIi%2FuRLHyGkfT8irQE4Jl8NjRPeNE7hmeZ6wMv8cW0xuBMsi5QpLrwdaoXfr7oSj0D5jlsYWiB7CZeggip5Luffr0PSZThugP4%2FZJ8rauoXpbX70WPl4i9fsmcGTm7goyQ4Zb%2FpLQNGDkzg%2F8sj38t9EDO5UQzuxloModhmGFAkoAXuB9FnaATvYH44DYRndUcauwHAFWNBjeir9JfZyXalqwTFku2lH7e6fHMQ48okr6%2B%2BU%2FGLYHaSZ1TPSpxke4CTqq3%2FcEAOJhLvCFyswDC04uCVR1n%2BLS54layW3jjz9ie6LA24nMGbCLLkfCpaItjYDvJ%2BnwkvuVikw5EiIKvhg%2BGhL4b3U%2BLlXkRjVxOa8r1c8aZMYVRlUWlSQeKHpN3MWBUGPkwuN2ZjHWicRhcD0r%2BQ8kkEgbJgHyqpR2qjq6tM5QgOQqAyXzhC49lKB7ag%2FeMLugogVAgHMgVkxPkZYnCq%2BRdJ5oFp4bihPLevZx9K8qosDdQrvlB5OebR4XLNZ8EzsApW66CVYLqqLLASU5dL7eQVRlOcQh6gvWY%2FPQblz5Q3L9L79kn1f8bXTCWpZu%2BBjqkAT2LxHmHvT%2B7e5NSj8%2FmRreiGrt8C%2Ft%2BLhjpvjN5nTnQ09WAbhwpAW17SiLOZpSAomlpfm7wEJXEGftlr%2Fa8erJQtf6ZMb5A%2FuxUD3A%2Fug2OjfnoMEwWsenmevAwKYvTrPYyNRxPgEWuWx9Z5%2FtBSG0e0i53cG%2FQtFyvWaZwfM%2BspCU56HumfLBE5IskwCW6s2MpGYWefAbtIJqxjc%2F9xcHk2RRi&Expires=1741695158\n",
      "tldrs download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/tldrs/20220513_073419_00109_m3j5m_02586bff-4a75-46c4-8f1f-e2d8ad0bbf75.gz?AWSAccessKeyId=ASIA5BJLZJPW3M7MGUN3&Signature=nMkCfOq46w86%2FNL%2FOyoICSeIRbA%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDh0yIv9blAslomOOO0rT9DqCRNYsgXlq%2Fd1VgwPAJiIwIgCmh%2BNKUWBDwqXbrbGGmSTQ%2BBJhmboZNbAc75Zm5XCtAqiAQI6f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDFLqyAny9N2YW4PHxCrcAyPkKb7zWjY7W3BqrdblYhyyJXhPJQ5hRMZ4Sx%2Fy92xJ%2FWYv76AR03BZphoZYc%2FN9tsRP9KOMid2jHbosxXkcEAgtOAG973c9zmzvs%2F1HXL%2BktB7yaX1N4VHDo%2BquFOhiXSoUnO7nY%2BunoBTbYKqfTRbyzTlSCK6FpqGpEOMNM%2Ftf4X%2BVGlzxYncboqB0KWFFyaZ2Q0Vwp8uYdXeZe%2BVoxnbbS9c9JmuVw6DG%2BkD5OJ7yiS2rSxJZ2Eu4%2FYri1%2Bh5XWU2b%2B%2FBwIhj6p80SQmweHiwiguINVibxeXygQ68kSTo3bqz%2BtWsQV6o95O7o3HlFOGMWGxgXER2g%2FdGjJLU5NToH3qVFctF4h8HAgC%2FpczlR%2BFlg%2B4LgmyocYAebxKMCp%2FeZ21K7gcACTNlaq8iCJD2mFtv6cM0re1oaLW%2Bz2Kq6NbwzVwfxjYJR%2BYn0%2BqDbVmo%2FInQUPYW3cubLaxqWCOrkVyfw4uES0E93C1poBB%2FbMNui2UTHUjrEGkyS8Uc6ANzWz%2FxmyixkgkoZb6uqIZILLKRgrfD6yH4mJYd%2FU3wq0PGGdkIbBsoI8DZ8FSQ0zbYhbUiMImaODcYN6mygRjsP870Q5mVyZWGKtes7%2Foq6vSp%2FlL4lAP%2FU9OMLvlmr4GOqUBIoAqStvegg0dB1PxriObxBZP0SUuvl7IDdBieddtmyiZH5JklYGZMEFZlhNn9O%2F0HkOle0mxeYZt2PRknf0EjJV7%2FUfGcIxAbbrSNE1d0AZcoryNZ8yaIqGJP7rtqBgohBgXppQIi5wkZa67O8le6WD8gJLjMpuBea48y88fRzqSMVKv5YSR9MW1A%2FBMj9nNbKxh2IOonwknA3JZBLHCw%2FH0R4T%2F&Expires=1741695159\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "# This endpoint requires authentication via api key\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "for name in dbs:\n",
    "    # Define dataset name you want to download\n",
    "    dataset_name = name\n",
    "    # Send the GET request and store the response in a variable\n",
    "    response = requests.get(base_url + release_id + '/dataset/' + dataset_name, headers=headers)\n",
    "    print(name+\" download url:\")\n",
    "    url=json.loads(response.text)[\"files\"][0]\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put each json file in a folder called rawdata and change their names to the appropiate ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start cleaning the data, we will start with the papers and keywords. First let's define the conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition for deleting a row\n",
    "def delete_conditions(json_obj):\n",
    "    if json_obj[\"publicationtypes\"] == None:\n",
    "        return True\n",
    "    elif json_obj[\"authors\"] == []:\n",
    "        return True\n",
    "    elif \"Conference\" in json_obj[\"publicationtypes\"] and json_obj[\"venue\"] == None:\n",
    "        return True\n",
    "    elif \"Review\" in json_obj[\"publicationtypes\"] and json_obj[\"venue\"] == None:\n",
    "        return True\n",
    "    elif \"JournalArticle\" in json_obj[\"publicationtypes\"] and json_obj[\"journal\"] == None:\n",
    "        return True\n",
    "    elif \"Review\" not in json_obj[\"publicationtypes\"] and \"Conference\" not in json_obj[\"publicationtypes\"] and \"JournalArticle\" not in json_obj[\"publicationtypes\"]:\n",
    "        return True\n",
    "    elif json_obj[\"s2fieldsofstudy\"] == None:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified JSONL saved to csv/papers.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"rawdata/papers\"   # Path to your JSONL file\n",
    "output_file = \"csv/papers.csv\"  # Output file where changes will be saved\n",
    "keywords_file=\"csv/keywords.csv\"\n",
    "RECORDS = 15000  # Number of records to save    \n",
    "count=0     \n",
    "# Read, modify, and save the updated JSONL content\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile,open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile, open(keywords_file, \"w\", newline='', encoding=\"utf-8\") as keyfile:\n",
    "         \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"corpusid\", \"title\", \"authorId\", \"authorName\", \"url\", \"year\", \"referencecount\", \"citationcount\", \"influentialcitationcount\",\"publicationtype\", \"publicationdate\", \"venue\", \"publicationvenueid\", \"journalName\", \"journalVolume\", \"journalPages\"])\n",
    "    csv_writer_2 = csv.DictWriter(keyfile, fieldnames=[\"sid\", \"keyword\"])  \n",
    "    \n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    csv_writer_2.writeheader()\n",
    "    \n",
    "    for line in infile:\n",
    "        if count >= RECORDS:  # Stop after 1000 records\n",
    "            break\n",
    "        try:\n",
    "            # Parse the JSON object\n",
    "            json_line = json.loads(line)        \n",
    "            # Check if the row matches the deletion condition\n",
    "            if not delete_conditions(json_line):\n",
    "                count+=1\n",
    "                json_line[\"authorId\"] = json_line[\"authors\"][0][\"authorId\"]\n",
    "                json_line[\"authorName\"] = json_line[\"authors\"][0][\"name\"]\n",
    "                if \"Conference\" in json_line[\"publicationtypes\"]:\n",
    "                    json_line[\"publicationtypes\"]=\"Conference\"\n",
    "                    json_line[\"journalName\"]=None\n",
    "                    json_line[\"journalVolume\"]=None\n",
    "                    json_line[\"journalPages\"]=None\n",
    "                elif \"Review\" in json_line[\"publicationtypes\"]:\n",
    "                    json_line[\"publicationtypes\"]=\"Workshop\"\n",
    "                    json_line[\"journalName\"]=None\n",
    "                    json_line[\"journalVolume\"]=None\n",
    "                    json_line[\"journalPages\"]=None \n",
    "                elif \"JournalArticle\" in json_line[\"publicationtypes\"]:\n",
    "                    json_line[\"publicationtypes\"]=\"JournalArticle\"\n",
    "                    json_line[\"venue\"]=None\n",
    "                    json_line[\"publicationvenueid\"]=None\n",
    "                    json_line[\"journalName\"]=json_line[\"journal\"][\"name\"]\n",
    "                    json_line[\"journalVolume\"]=json_line[\"journal\"][\"volume\"]\n",
    "                    if json_line[\"journal\"][\"pages\"] is not None:\n",
    "                        json_line[\"journalPages\"]=re.sub(r'\\s+', '', json_line[\"journal\"][\"pages\"])\n",
    "                    else:\n",
    "                        json_line[\"journalPages\"]=None\n",
    "                \n",
    "                row_papers = {\n",
    "                \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                \"corpusid\": json_line.get(\"corpusid\"),\n",
    "                \"title\":  json_line.get(\"title\").strip().replace(\"\\n\", \" \"),\n",
    "                \"authorId\": json_line.get(\"authorId\"),\n",
    "                \"authorName\": json_line.get(\"authorName\"),\n",
    "                \"url\": json_line.get(\"url\"),\n",
    "                \"year\": json_line.get(\"year\"),\n",
    "                \"referencecount\": json_line.get(\"referencecount\"),\n",
    "                \"citationcount\": json_line.get(\"citationcount\"),\n",
    "                \"influentialcitationcount\": json_line.get(\"influentialcitationcount\"),\n",
    "                \"publicationtype\": json_line.get(\"publicationtypes\"),\n",
    "                \"publicationdate\": json_line.get(\"publicationdate\"),\n",
    "                \"venue\": json_line.get(\"venue\", ''),\n",
    "                \"publicationvenueid\": json_line.get(\"publicationvenueid\", ''),\n",
    "                \"journalName\": json_line.get(\"journalName\"),\n",
    "                \"journalVolume\": json_line.get(\"journalVolume\"),\n",
    "                \"journalPages\": json_line.get(\"journalPages\")\n",
    "                }\n",
    "                # Write the row to CSV 1\n",
    "                csv_writer_1.writerow(row_papers)\n",
    "\n",
    "                keywords=list()\n",
    "                for keyword in json_line.get(\"s2fieldsofstudy\", []):\n",
    "                    keywords.append(keyword[\"category\"])\n",
    "                keywords = list(set(keywords))\n",
    "                for keyword in keywords:\n",
    "                    row_keywords = {\n",
    "                        \"sid\": count, # We will use the surrogated ID here, just in case\n",
    "                        \"keyword\": keyword\n",
    "                    }\n",
    "                    # Write the row to CSV 2 for each keyword\n",
    "                    csv_writer_2.writerow(row_keywords)\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "print(f\"Modified JSONL saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

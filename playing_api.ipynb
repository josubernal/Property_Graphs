{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the databases of the API with the following code. We will be using the oldest version of the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"release_id\": \"2022-05-10\",\n",
      "  \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThese datasets provide a variety of information about research papers taken from a snapshot in time of the Semantic Scholar corpus.\\n\\nThis site is provided by The Allen Institute for Artificial Intelligence (\\u201cAI2\\u201d) as a service to the\\nresearch community. The site is covered by AI2 Terms of Use and Privacy Policy. AI2 does not claim\\nownership of any materials on this site unless specifically identified. AI2 does not exercise editorial\\ncontrol over the contents of this site. AI2 respects the intellectual property rights of others. If\\nyou believe your copyright or trademark is being infringed by something on this site, please follow\\nthe \\\"DMCA Notice\\\" process set out in the Terms of Use (https://allenai.org/terms).\\n\\nSAMPLE DATA ACCESS\\nSample data files can be downloaded with the following UNIX command:\\n\\nfor f in $(curl https://s3-us-west-2.amazonaws.com/ai2-s2ag/samples/MANIFEST.txt)\\n  do curl --create-dirs \\\"https://s3-us-west-2.amazonaws.com/ai2-s2ag/$f\\\" -o $f\\ndone\\n\\nFULL DATA ACCESS\\nDownloading the full data requires an API key, which can be obtained at https://www.semanticscholar.org/product/api#Partner-Form\\nFor access to the full datasets, see https://api.semanticscholar.org/api-docs/datasets.\\n\\nLICENSE and ATTRIBUTION\\n\\nSee the README files for each dataset for information about licensing and attribution.\",\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"name\": \"abstracts\",\n",
      "      \"description\": \"Paper abstract text, where available.\\n100M records in 30 1.8GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"abstracts\\\" dataset provides abstract text for selected papers.\\n\\nSCHEMA\\n - openAccessInfo\\n   - externalIds: IDs of this paper in different catalogs\\n   - license/url/status: open-access information provided by Unpaywall, linked by DOI or PubMed Central ID\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"authors\",\n",
      "      \"description\": \"The core attributes of an author (name, affiliation, paper count, etc.). Authors have an \\\"authorId\\\" field, which can be joined to the \\\"authorId\\\" field of the members of a paper's \\\"authors\\\" field.\\n75M records in 30 100MB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"authors\\\" dataset provides summary information about authors.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Author-Data\\n\\nThis dataset does not contain information about an author's papers.\\nInstead, join with authors.authorId from the \\\"papers\\\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"citations\",\n",
      "      \"description\": \"Instances where the bibliography of one paper (the \\\"citingPaper\\\") mentions another paper (the \\\"citedPaper\\\"), where both papers are identified by the \\\"paperId\\\" field. Citations have attributes of their own, (influential classification, intent classification, and citation context).\\n2.4B records in 30 8.5GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"citations\\\" dataset provides details about one paper's citation of another paper.\\n\\nSCHEMA\\n - isinfluential: true/false if the citation is considered influential. https://www.semanticscholar.org/faq#influential-citations\\n - contexts: Text surrounding the citation in the source paper's body.\\n - intents: Classification of the intent behind the citations. https://www.semanticscholar.org/faq#citation-intent\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\\n@inproceedings{cohan-etal-2019-structural,\\n    title = \\\"Structural Scaffolds for Citation Intent Classification in Scientific Publications\\\",\\n    author = \\\"Cohan, Arman  and\\n      Ammar, Waleed  and\\n      van Zuylen, Madeleine  and\\n      Cady, Field\\\",\\n    booktitle = \\\"NAACL\\\",\\n    year = \\\"2019\\\",\\n    url = \\\"https://aclanthology.org/N19-1361\\\",\\n    doi = \\\"10.18653/v1/N19-1361\\\"\\n}\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"embeddings\",\n",
      "      \"description\": \"A dense vector embedding representing the contents of the paper.\\n120M records in 30 28GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"embeddings\\\" dataset provides embeddings representing a paper's contents in vector form.\\n\\nThe model is based on the SPECTER model available at https://github.com/allenai/specter. However, the embeddings\\nincluded in this dataset are not compatible with the embeddings produced by the pretrained model from that repo.\\n\\nLICENSE\\nThis software is released under the Apache 2.0 license. (https://www.apache.org/licenses/LICENSE-2.0)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{specter2020cohan,\\n  title={{SPECTER: Document-level Representation Learning using Citation-informed Transformers}},\\n  author={Arman Cohan and Sergey Feldman and Iz Beltagy and Doug Downey and Daniel S. Weld},\\n  booktitle={ACL},\\n  year={2020}\\n}\\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"papers\",\n",
      "      \"description\": \"The core attributes of a paper (title, authors, date, etc.).\\n200M records in 30 1.5GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"papers\\\" dataset provides core metadata about papers.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data\\n\\nThis dataset does not contain information about a paper's references or citations.\\nInstead, join with citingPaperId/citedPaperId from the \\\"citations\\\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"s2orc\",\n",
      "      \"description\": \"Full-body paper text parsed from open-access PDFs. Identifies structural elements such as paragraphs, sections, and bibliography entries.\\n35M records in 30 3GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"s2orc\\\" dataset contains parsed full-body text from selected papers.\\n\\nA subset of this data was previously released (in a different format) as S2ORC https://github.com/allenai/s2orc\\n\\nThe body text is parsed from PDF documents using Grobid, documented at https://grobid.readthedocs.io.\\nIts output is converted from XML into a single string with a set of annotation spans.\\n\\nSCHEMA\\n - externalIds: IDs of this paper in different catalogs\\n - content:\\n   - source:\\n\\t   - pdfUrls: URLs to the PDF\\n\\t   - oaInfo: license/url/status information from Unpaywall\\n   - text: Full body text as a single string\\n   - annotations: Annotated spans of the full body text\\n\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\n@inproceedings{lo-wang-2020-s2orc,\\n    title = \\\"{S}2{ORC}: The Semantic Scholar Open Research Corpus\\\",\\n    author = \\\"Lo, Kyle  and Wang, Lucy Lu  and Neumann, Mark  and Kinney, Rodney  and Weld, Daniel\\\",\\n    booktitle = \\\"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\\\",\\n    month = jul,\\n    year = \\\"2020\\\",\\n    address = \\\"Online\\\",\\n    publisher = \\\"Association for Computational Linguistics\\\",\\n    url = \\\"https://www.aclweb.org/anthology/2020.acl-main.447\\\",\\n    doi = \\\"10.18653/v1/2020.acl-main.447\\\",\\n    pages = \\\"4969--4983\\\"\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"tldrs\",\n",
      "      \"description\": \"A short natural-language summary of the contents of a paper.\\n58M records in 30 200MB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"tldrs\\\" dataset provides short natural-language summaries of a paper's content.\\n\\nThe model is based on the SciTLDR model available at https://github.com/allenai/scitldr.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@article{cachola2020tldr,\\n  title={{TLDR}: Extreme Summarization of Scientific Documents},\\n  author={Isabel Cachola and Kyle Lo and Arman Cohan and Daniel S. Weld},\\n  journal={arXiv:2004.15011},\\n  year={2020},\\n}\\n\\n\\n\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://api.semanticscholar.org/datasets/v1/release/\"\n",
    "\n",
    "# Set the release id we will work with the first release\n",
    "release_id = \"2022-05-10\"\n",
    "\n",
    "# Make a request to get datasets available the latest release\n",
    "response = requests.get(base_url + release_id)\n",
    "\n",
    "# Print the response data\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "res=json.loads(response.text)[\"datasets\"]\n",
    "dbs = []\n",
    "for dataset in res:\n",
    "    dbs.append(dataset[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each database is really big and because of that it is divided different downloadable parts. Let's list the first link of each part, click on it to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstracts download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/abstracts/20220513_070629_00025_mtwkq_0b601c4a-dca2-4eab-921b-1c86bcba0147.gz?AWSAccessKeyId=ASIA5BJLZJPWV4IQXRFZ&Signature=ub6RkmV1DIeT7YctnfZDpGKeMT0%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEMv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIH8fAKDF0J3RAmWi%2FFCeSg0zCX1ETGWnHOZ%2BgDTgeWyqAiEA0EvDToJJR2uICdIfo5gc7yScXg%2FyCPi%2Bz3UUeRqCWjwq%2FwMIFBAAGgw4OTYxMjkzODc1MDEiDA9dRDpcG%2FWDtnl1eircA4KFxd3%2BpoQ2jl1Im2eQPtyq20ixJx6kOw1e3lnwU1nSHG0vkIz3TTrSrFfAlW01B%2B82PKmPjARceLzCRIdH811%2FI2STtNiTopP4A02LpSiq1zW4M1OlbHtXq8QknsyKPkWehzPjQHoNSa%2FjPSGC2ymBnZqmC6mIQREln2iXnnoN9qUWvBQIJ03Gvs%2FBJrg1kYciuChnXQqxpVyHGjP%2FkXOBZvW%2FsPHP5q1gB2UOcPvYRMVe2ABF5Tn%2Fiw59Z231aEuH3MjcH5UvWGc4Hy9JF2eqpde7b49dOeHTDDdyFDch28OqMbVg%2BP7m6HYPt%2BZv8u9dgZA%2FflQWmqBGpbzLZD8HH%2FLskBNSvAy5SfxkpF%2BNdx5PvDBUP2ehJBdALxhHq%2BrdE35URlXU8XM8Mga1kogILTRJtqrqo6MozfcFMZvQoVet0WQ%2FlOtHyG2GpthLQ9L4NxMyLZblzj7DSnL8z%2FqGUjicdCMxN9MRyo1Jh8AzQiqzO3uTBRAwzIft4EHuGkgW5TsAVRpzbwEwaVUprCZy3cmdLhtXZ2M8NVc3t3AznwWruE%2B2ifd3BmwCouP6KiJE%2FR8pgjw2NQ9fYT6PqnIn69LTeD42y5dTyKB5AfFlxJQjhhKIWsx%2BzSABMJLPoL4GOqUBM9PKg9rEUdwZRwihppTdcKKcqCPzq7uf6%2FQ3MImwi7uXbmgNZTgKVBgaqUNfE%2B3okD1QdTnP%2BWZMuOJP71QpZh9VLZc9hM9kgdaQHEcv8W0vPUtUicY8DugL4xfTYHR3dNdcfyfZBXovAJ3PAU4LOziSMWhYCr0ixg6zfOy6ir4vdjXhhKgda2cu4R3UkJRA9XItL5QsLkgs9PyEXNKMgPl66cAz&Expires=1741790317\n",
      "authors download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/authors/20220513_071222_00034_g4b97_046945fe-8bc5-4e7b-8bca-95cc504838e8.gz?AWSAccessKeyId=ASIA5BJLZJPWXYEBHI72&Signature=wJiCUnQh2Eoa0HzLs1%2BTpa9XtgM%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQD0ArBpN8GVvDeZKUHnz%2BGc1%2B4yLlSmy5eoGEFsh1euwQIgY0cq78Z4BeZQ0Cy1XIAOlVW%2B0%2BrEu3KldhMJ43W9hZIq%2FwMIFxAAGgw4OTYxMjkzODc1MDEiDDmPSj7otk3TV8gRUyrcA7mLfifxs%2BHoXQxKXh3DmHlXj8AfLGRrX55jZOotTBZYAkPffYnGHVCr8TFN2wW1iHdYlrkeXah8yrFBthkVV9I8qYFpizsYng2ngjew6AwfOHuqVlNpNPjDAFt48%2BC7wf4oLa4hUWUKJx59ob3vn8%2FDjdjve0S%2FWE9W1PY75qMCqdOpk%2B7VKDgY5wyG40%2FglP3xYdOXMUI7HgejKJ%2BhdmkjgFY3vPMRTbvHGVmEvkE9%2BjcT8hp9p1cL%2BOplQbt%2F%2F1YgHrKwNOOSYOSz8EF42bBanMBQXu7TQMQf09xQHg0tHCZbE%2Bk1pl01FA8G9b1VQZ48CGglJ2bg%2FzpIliTUPf7%2B5PEpaNMhCvpXmWls%2FgeassL%2FcPhWHVunKpOlVGhw9LBaEyqg%2BlgpXhCaNyviGnjNAGaJbWXxM3RIrFvEWJfBb1emvrh3NmHvTnIME6na1cmPc1geoquUOOmFh20FCSCReBsRTg%2F5JmAaugbeweKWelHu%2FjLRv6M1A32y0fo7iLaNXJdMFxCq2QmdieyPrMomTEV5YUwZfbdS6LdCUmA8Z%2Blfxa3X%2B5Ne1Md09uK8sGHjvJBEM9vVwPknAlUDOXil%2FL4O2sYrqxp9N8Ern41zn8Zp2QI%2B1FRAneOoMKiiob4GOqUBPj0AvHMXk%2B%2F2hjvJNCgW7MT8sgsZdxgmbRCTYX7xVai81mEGBIAMegoipkybdnHVCjqa41ImAYnCn1NkHFVtbw24TJVT0wMi2QeOozLQ%2Bao1GkBSPM9v68GTeVaEnV5LTYP6Mu3iP1Lsm%2BqN6dwUIYEUgr4p2PE%2FCiwi6xwen3%2FstH2Weoo%2BxMr2Kd7ThWXlSNYf7mdcBbDJYCqn6C6eawnE0A7t&Expires=1741790318\n",
      "citations download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/citations/20220513_071330_00037_xkiix_00bc87b3-00b5-4912-91e0-2e7ea0a433a0.gz?AWSAccessKeyId=ASIA5BJLZJPWXRBQBYVN&Signature=bS%2FIs%2Ba77hJ5JXXwdjJ2ft3dKQM%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEMz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDreoiBpwkZv63mDlR1rdTPPsQ2U1gS55HrlTtcGLFcMgIgaWEazsatwlCDoN4LWL2Cr80hmf34E8h92tXHYIaKWxQq%2FwMIFRAAGgw4OTYxMjkzODc1MDEiDJBAP4ouRyJwwcUANircA0WIziDmeyGupH3UOa5LEiOk53qlKXMY8VFyhB5yIXw8FnIxSMwtKPTHXnwssXXEUq6yItOlbNAHXFKAU6CKyflmoJwtPmLfpN%2FO1PZcbefLtV6w%2F0aTsShM7IxJ%2BoB6fNFy4FfEaUvB%2FHj3GMFapY4r3PzivhwT%2Fn0ACvhRfqN%2B0v99R6fF6oYQXmCRN6c%2FHzwuimnee1BAJwP6RELOMTLuAjTrdWzJWDS31Cm9%2FqgwJov9dS9GY6gLVoM9ppxkmSM2EHQDP82gX7TSW2EpS%2Fan1ZvlDgBoypDzAmzF6pjuB7aCJAHW6LI%2F%2FRLDt9uHsHJdfJLUNwVzhnLgc5GAY6Qis8MPo38xpsW%2B1LVLsK0GlnR4sXWoUs%2BmFuLZ3jK52EnEquDPJ78QWwSSDqhEIYfGZhXfHLsIlUDVL4lW19%2FDignDk9m4Fj%2F198ZXUYGIFvQfFsz1bfDCmB0HrmyaoK7kA0O9ZctrmjyASXwORwOx0ZIBkFxdgM6%2Fjp8lNURUcireo1orUnDQR6GjG368bKiU%2BvhhgPNiWqlxw7ibbyATiy4BoygkD2ZHbBvJO%2Fx2NPC%2FcGxOPHCSGOnqrkPmg7Yz%2Bs5KX%2BZOSTytGHKVy%2BCTbFtEURsSAvmVR3qrMPf2oL4GOqUB5QPSNpo9If7G3o6HhlhXwSFYQh27eMDMAW4eZPRHyTZV8oQpMOEpIdqc82bIVlRougnjLo0JLPRXmxGaT4MGV98PqjaT%2BYurJrN%2BUnLLR8ti1UJdBqy%2FTj5CMQvqgBC2boXeuWm09puPG9eF9GCZ15EZShG0p7vhWiyf0Hs0dqAWIebEj%2FfhHX%2BYa0ipqIkEazEDzBKoYL%2BpHQIg9sz%2F65RUgDt8&Expires=1741790320\n",
      "embeddings download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/embeddings/20220513_073500_00025_jcu4c_08b8baf2-dfe2-4d95-804a-01e951f4b532.gz?AWSAccessKeyId=ASIA5BJLZJPWWX7UMFOX&Signature=CkL6sKQTCZ8w%2F%2FYuviZ32EB3aMk%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCodCsH1RuiaFsLM%2BylH%2FpECT6kTIGaotTw%2BJ%2FkOgrmFAIhAOS1XRs5RyK9jmDflAX8IoIiPDsUosZu8NyYj7u3c7GDKv8DCBcQABoMODk2MTI5Mzg3NTAxIgxasMfYxTqDawrtAO0q3AOUfAjEyiX8aNyRjU8MlMpSahi6X%2FwcabH8KvNBvUBFaQsD2b%2BT48AKBSm67dcRYRVeyPCe2qLIn6uU3PasyjS9sLBakBeftGo%2BEH2y5XsXdjUv7fcImPV8lkR9MlP7SR0dzPk6l6KH9k4oHQq1iM%2Fv2uXkerT%2FH%2FxwEo%2FBsvK3nWwVoGtC%2BL18pQVNR6ijiEHG%2BH%2Fhy8VpjYdQEUc43BFgfgeX7bdd5nL4KwXSKBUmkUFvewZXSRk2%2Bz4e%2FOqZAb5uAFCAC%2BdqKehlfwHOC1U1nK4jAHgAxXBe6icGa%2B8llCOOth5YiT3bQDPUpVOm3rsZrkfGbgmpV4kwh%2BxGcdIoweo7v5jC2k51P9Kjpb2lI3OST39zd3jsMZVRFWZ7r8x8fPSWsMCEKyrS8wvSrsBC%2FxROmCBYLKjxuMmTd8POvjSUkzQJS7nJOe%2FWz6XWrONmy%2BaUdq1A8p4h9FauDDgdQCI50zGgxwfJ9gzgt2yWz%2FIJ1BbrIy93S%2Fiow74sjTWPOMiD%2B9h4oK9oXIhTScmoj4Oz%2BBGrqLrPsnpIp2JjOvpqWs%2Bd0L4kkveaeOYDUaSOsoDMLp6zdCrQmL3hQRoLe3KBExLu66voK9McVjSKmTy%2F5PFydKbIjRw7STDurKG%2BBjqkAQkMUXNc3Y3JqHxOrPzQvSMMZ26LCj7GfNs00dxd%2FiqMY88mkDfrRblJSD%2BHgwC6tyeV8PmcSyUw%2FVp43qJ4RjbKWlr7lSqC5e5ZN8PFV2pb%2BGzTSShDDH6KFvL4%2BDDd9akPFXQcEcLHelhrlamKSCmbV3OJtR9v2uG2gbLF5QA2vT6qho7UAeVPU9aqciDFq75x6xSL17uvaKC8qA7KXi0Bf3YA&Expires=1741790321\n",
      "papers download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/papers/20220513_070151_00012_4bpee_054cd248-48ad-47d6-b0d9-e4fe4333cc61.gz?AWSAccessKeyId=ASIA5BJLZJPWRCVT7POI&Signature=odFWgPm9tQd1gjGqCUFGZk%2Bra%2BE%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEMz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIBmS%2FfT4zgQo2oeRv60nFL0TsAi88zT%2BF3L2OPGuFIbEAiEAwIet41mtyFlTR16dOdJxzrZRKRnhce3jlk7r8r1yP7Uq%2FwMIFRAAGgw4OTYxMjkzODc1MDEiDAWVmhIW0KBE2BsDtyrcAwVIHWR9EZz7M%2BcWc4YpNU2PI3Q8fIeV7sSe0Heh5uf64qsbke0R1Q0p5Ifp2BKt7jCTgBQcu2Tfy46Sp54okum83GEbUnuiLGAPJhvG%2FribSjtNKa3pG1m4TJiBs04WO8BMVBRr6jc8iuGcQ%2B9nOynRNL%2FVu0IUQjoUbMWkhicruF1BzXsLpv8cnVR8DXE04Xpj%2B%2Fen3FcTmNwPeb9WvyT6Zmz91r3GfzjJqhBAFKF%2BhWZoffQwCzIJq%2FpKERXH0zaeuuSDu7hkI8GYSbyN27QLTcpYnigEXwqQiK7Nf5aoz%2BrLBBqd6Wzeu5Owj1nPg7Hr53RDCi2qkbEqVChb9LN1TTHYt4grWzm2jgW%2BhOWVWTW%2BoJSx2HYI7kclmuQAT58gyRUoL03Uh0ykjZugOoTQsiJKad5HW2GupVRFb3qKRtXhYKWx0vSiOFclbkGEixfTVpHck0%2BE%2BBFcPlzplUdA83qCCL16T48UYCxiUtcFBVpRG%2FSiHOdx0pXL%2BN5oQ8NxxgEgkeTawZjpx1eghqM6GW4XJK%2FmmT3j%2BPGGH%2Bm5RydRYm2LF6ubLh0MJfDVyqCXEo7qvX%2BT8QHRte0l58of2gmJj4qX5NmdVbBM8cGp%2BkOY03T9vUFpZyQzMOrtoL4GOqUBXCTioy7TGjhSxkrK9K6jaGMwZzNNDZ2msYPPtxyyMJw3bwVAL0xdgt3LBTMGe9YhrnBHmPxORUm5sklH8xY4oDh186426d4wEwubihurIcdCRfPFsNBxYBo%2FWds4IWaivtaKvZIeBZyrVoOTuJBpEdZWxCn1eNgAKjfvrR7cVHnQ2R7K7jPn%2FDZTvq7NWgcU2AJ2%2FFRum6SXXEOLs%2Bn7r8shk3gN&Expires=1741790322\n",
      "s2orc download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/s2orc/20220519_000932_00025_dauyy_04c9ef07-dd83-42f4-b36a-4d3ea06c99b0.gz?AWSAccessKeyId=ASIA5BJLZJPWSRMIY22M&Signature=dTLx7VN9FNnJFMUN78203i19izo%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEMz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJGMEQCIH3CoGeeaIJBMSSQYS05ZVEHXIbjtRSssis6WqL2G%2BG3AiBGUbdLOzlESQpfOzczEmGYozYLH%2BYfmCmF%2FkIS7C2Njyr%2FAwgVEAAaDDg5NjEyOTM4NzUwMSIMZqjWl8naLR7L8PWrKtwDtojsgP3MCxB2IBriHgX1F8yM87l6Lq9SoYHKiiHvJMEwLJzHzei%2FmDkXXL%2Fxm3fnjQ7u9LxGD%2F7cpU3CmrjGfYPPhFza2gy8dLs5YcHfUBovKb3cbO7sO6hkkAbDmlJnFYezqPcLYHNtPAPJZaj6jOLpEgl9r%2F7tgPDjRQ6MxVfG53iLHOdKLX0pki%2FMJaJ%2BGEXK8vMKnywyhAZcRWeYPuZiR4EXtHzRvI7AS4rd2mhfzL2dirajeJZipEcfQ3N6r2r29cyH1jdSrnw65h5NnoW4IYfE5JzXDL5IM19l9LywkSv94Wh9disDMZuxJM4TzYqoTuzitcDTkh7T63e2H4N%2Fb8uclTp3IPPOraTvH%2FCqBeGpVCdVgQ1CbYxxuapE%2Fv3sMMThRfYXTZUNFEr2iVQQ0WoO7jikhDpyZeG3ARE6ZNxwKck4gB43ZEIWRTYyZg8V2IV1RSz59Qi4PmioTXvfKwu32yR2hlW5kwE9Yd1U4vtO8SyOXukMpaZhZ3Mvpesgz7GAMtmcS%2FabofaMMH0bIX%2BigpHBlPM174EtjhGb%2F7i9J95gNk%2Bei2aAug5L6TUVRgYW9yk%2FRMv3VeCH55YRJ%2FiICK%2F7CQwRC1PZKwISRdPzcpnTAhll3o0w5vugvgY6pgG3TV3FyLYDYGt2jNd5NhpiEy280cZ06JadKWE45ZuVYvs2surrkSIgCp%2B0vFIS%2BZs9%2Bi7yxW0SX0r%2Bx0yqW5y6zTNDSgJRSokzknh1%2Bz3kHiYsOxaVNjAqasa2Eu5uiSuPu9ie5dMg1hCo2Ohxs%2B3WbbYTs%2ByuiQvfgZsh%2FTRYZX9uyCP5hRyJycn%2FGmDmIRGd3nHCT%2BC%2BMlsnWMeJzKhL0SxQPCgU&Expires=1741790323\n",
      "tldrs download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/tldrs/20220513_073419_00109_m3j5m_02586bff-4a75-46c4-8f1f-e2d8ad0bbf75.gz?AWSAccessKeyId=ASIA5BJLZJPWQH7YB6SZ&Signature=ygGg3lDR7hgkSBXpwYmnr%2F1T97c%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCICcmlNYU8AmokiDwy4dQpdLUxiwuNEo%2BlvVwEgdKhFa%2BAiEAl7fFZSw86JE0YKiORVFmH6lHtLJGmHlxccVIuzX%2F1Ocq%2FwMIFhAAGgw4OTYxMjkzODc1MDEiDKlQJf%2BsK%2FYkvUKqAyrcA83EEJQeZ%2FOZtv2C%2BAxfYw8l1SgexlDsK5LJQmCc3Yll5mEO7KHIxA%2B89uzH8QrFZQnA%2FSP0VLm1nfD39WY18fNCN68%2BopRjZkVMoqLca82Jgww5821QSgDhMIY9fRnTp%2FQirnQxd0IVzFtrojHgsFADlydytZ9LjDwOYXTw6q7zY0FFXQRTn%2FGAOYvpM%2BHiO2LPh9J22ycDCay%2Fi%2FCODxVF0KCjOsl0jPfa4XXmGfwwO26Jyqslfuo7yW58kdjq3wyFBG3heiAKwQyO9sxQYmpkioputPUfaK8FfngkBcMAnmHJPT8ey9A%2BXGcHRiSUcZMH%2BPRkcoLElKRaTUQdu6cCAu%2FX6nATc2GDcDxAbhwHQh2Dvm7wo2fhpPjWyvEPGZhNVPdaOd9QM1x%2BcxPk2au9TJGuj2HqZduBiaoygHT3hVQ%2FtbvmBWLNawaaD9YZkfm9weUzFzm4DYBpnVdHvgnWX9368RLv6k2XGEQT%2FT2MNJbxdPm5Z0sA1g8gdsAVTM9zmBw%2FPylyJePw5AuPnBHjC5lMGB9WlXOWZhChOZS5FE%2BYDi1v6cpkSrFmhmySv8gE2O8DRB%2BI6hRUhPB9XqeEpby82AB6wkoJum3jmRQpVuaNA5%2FPZMHSoDTJMMmFob4GOqUBPOCyY7Fw%2B4k98p89zJvAl%2BIKRKW5nnTBHqjGqgtsSBOEv%2FJy1y4O83kbzBSx0anAf4px6aPhxU3J%2BA0aR5omnXjrhB%2BMp1d5R8Cjw%2BVzsWfitEnmmz3YCz12BZ%2Fd9aBwevyCrdyhmc4o7JAPzkcGBobJyIXi4u83eIWl%2FCjzN4SjAis6uE92GL8krdayydVmvvzaWSpEJW%2BC9XqoXHNiSZUsqNx8&Expires=1741790324\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "# This endpoint requires authentication via api key\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "for name in dbs:\n",
    "    # Define dataset name you want to download\n",
    "    dataset_name = name\n",
    "    # Send the GET request and store the response in a variable\n",
    "    response = requests.get(base_url + release_id + '/dataset/' + dataset_name, headers=headers)\n",
    "    print(name+\" download url:\")\n",
    "    url=json.loads(response.text)[\"files\"][0]\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put each json file in a folder called rawdata and change their names to the appropiate ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start cleaning the data, we will start with the papers and keywords. First let's define the conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition for deleting a row\n",
    "def conference_conditions(json_obj):\n",
    "    if json_obj[\"authors\"] == []:\n",
    "        return True\n",
    "    elif json_obj[\"venue\"] == None:\n",
    "        return True\n",
    "    elif json_obj[\"s2FieldsOfStudy\"] == None:\n",
    "        return True\n",
    "\n",
    "def journal_conditions(json_obj):\n",
    "    if json_obj[\"authors\"] == []:\n",
    "        return True \n",
    "    elif json_obj[\"journal\"] == None or \"name\" not in json_obj[\"journal\"] or \"pages\" not in json_obj[\"journal\"] or \"volume\" not in json_obj[\"journal\"]:\n",
    "        return True\n",
    "    elif json_obj[\"s2FieldsOfStudy\"] == None:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified JSONL saved to csv/papers.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = \"csv/papers.csv\"  \n",
    "keywords_file=\"csv/keywords.csv\"\n",
    "\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "#********************************************************************************************************************\n",
    "RECORDS = 50  # Number of records to save per cathegory \n",
    "PUBLICATION_TYPES = [\"Conference\", \"JournalArticle\"]  # Publication types to filter (There is not Workshop)\n",
    "QUERY = \"data\"  # Query to filter the papers\n",
    "FIELDS = \"paperId,corpusId,title,abstract,authors,url,year,referenceCount,citationCount,influentialCitationCount,s2FieldsOfStudy,publicationDate,journal,venue,publicationVenue\"  # Fields to retrieve from the API\n",
    "#********************************************************************************************************************\n",
    "\n",
    "query_encoded = urllib.parse.quote(QUERY)\n",
    "fields_encoded = urllib.parse.quote(FIELDS)\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile, open(keywords_file, \"w\", newline='', encoding=\"utf-8\") as keyfile  :   \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"paperId\",\"corpusId\", \"title\", \"authorId\", \"authorName\", \"url\", \"year\", \"referenceCount\", \"citationCount\", \"influentialCitationCount\",\"publicationType\", \"publicationDate\"])\n",
    "    csv_writer_2 = csv.DictWriter(keyfile, fieldnames=[\"sid\",\"keyword\"])\n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    csv_writer_2.writeheader()\n",
    "    for publication_type in PUBLICATION_TYPES:\n",
    "        type_encoded = urllib.parse.quote(publication_type)\n",
    "        url1=\"https://api.semanticscholar.org/graph/v1/paper/search?query=\"+query_encoded+\"&publicationTypes=\"+type_encoded+\"&fields=\"+fields_encoded+\"&limit=\"+str(RECORDS)\n",
    "        response = requests.get(url1, headers=headers).json()\n",
    "        for line in response[\"data\"]:\n",
    "            count += 1\n",
    "            try:  \n",
    "                if publication_type==\"Conference\":\n",
    "                    if not conference_conditions(line):\n",
    "                        line[\"publicationType\"]=\"Conference\"\n",
    "                        line[\"journalName\"]=None\n",
    "                        line[\"journalVolume\"]=None\n",
    "                        line[\"journalPages\"]=None\n",
    "                    else:\n",
    "                        continue\n",
    "                elif publication_type==\"JournalArticle\":\n",
    "                    if not journal_conditions(line):\n",
    "                        line[\"publicationType\"]=\"JournalArticle\"\n",
    "                        line[\"venue\"]=None\n",
    "                        line[\"journalName\"]=line[\"journal\"][\"name\"]\n",
    "                        line[\"journalVolume\"]=line[\"journal\"][\"volume\"]\n",
    "                        if line[\"journal\"][\"pages\"] is not None:\n",
    "                            line[\"journalPages\"]=re.sub(r'\\s+', '', line[\"journal\"][\"pages\"])\n",
    "                        else:\n",
    "                            line[\"journalPages\"]=None\n",
    "                    else:\n",
    "                        continue    \n",
    "                line[\"authorId\"] = line[\"authors\"][0][\"authorId\"]\n",
    "                line[\"authorName\"] = line[\"authors\"][0][\"name\"]\n",
    "                row_papers = {\n",
    "                    \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                    \"paperId\": line.get(\"paperId\"),\n",
    "                    \"corpusId\": line.get(\"corpusId\"),\n",
    "                    \"title\":  line.get(\"title\").strip().replace(\"\\n\", \" \"),\n",
    "                    \"authorId\": line.get(\"authorId\"),\n",
    "                    \"authorName\": line.get(\"authorName\"),\n",
    "                    \"url\": line.get(\"url\"),\n",
    "                    \"year\": line.get(\"year\"),\n",
    "                    \"referenceCount\": line.get(\"referenceCount\"),\n",
    "                    \"citationCount\": line.get(\"citationCount\"),\n",
    "                    \"influentialCitationCount\": line.get(\"influentialCitationCount\"),\n",
    "                    \"publicationType\": line.get(\"publicationType\"),\n",
    "                    \"publicationDate\": line.get(\"publicationDate\"),\n",
    "                }\n",
    "                csv_writer_1.writerow(row_papers)\n",
    "                \n",
    "                keywords=list()\n",
    "                for keyword in line.get(\"s2FieldsOfStudy\", []):\n",
    "                    keywords.append(keyword[\"category\"])\n",
    "                keywords = list(set(keywords))\n",
    "                for keyword in keywords:\n",
    "                    row_keywords = {\n",
    "                        \"sid\": count, # We will use the surrogated ID here, just in case\n",
    "                        \"keyword\": keyword\n",
    "                    }\n",
    "                    # Write the row to CSV 2 for each keyword\n",
    "                    csv_writer_2.writerow(row_keywords)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "print(f\"Modified JSONL saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"paperId\": \"ad7ddcc14984caae308c397f1a589aae75d4ab71\",\n",
      "    \"references\": [\n",
      "      {\n",
      "        \"paperId\": \"cec7872b194aadf54140578b9be52939eb1112e9\",\n",
      "        \"title\": \"LambdaNetworks: Modeling Long-Range Interactions Without Attention\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"b52431a4268bd2f848db4a0c8c614dc1e687eeab\",\n",
      "        \"title\": \"Grafit: Learning fine-grained image representations with coarse labels\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a\",\n",
      "        \"title\": \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"64b9be00f4eecd465b4e8e46e2ab7624d7eaeb2b\",\n",
      "        \"title\": \"Global Self-Attention Networks for Image Recognition\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"867ec3a4837213d0096fec75aa6d1dbbfd2c4b1d\",\n",
      "        \"title\": \"Feature Space Augmentation for Long-Tailed Data\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8\",\n",
      "        \"title\": \"Generative Pretraining From Pixels\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5156381d63bb3e873533b08f203cb56c2d79b6c9\",\n",
      "        \"title\": \"Object-Centric Learning with Slot Attention\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f5c8464032a936451b222be1984cabf42d6adfa8\",\n",
      "        \"title\": \"Are we done with ImageNet?\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a0185d4f32dde88aa1749f3a8000ed4721787b65\",\n",
      "        \"title\": \"Visual Transformers: Token-based Image Representation and Processing for Computer Vision\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"13da774fe604027bff2951ba82f4c3d9be7e415e\",\n",
      "        \"title\": \"Augment Your Batch: Improving Generalization Through Instance Repetition\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5335fe1bf347f7ad1dce1611ea4b60bd8391a090\",\n",
      "        \"title\": \"Transferring Inductive Biases through Knowledge Distillation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"962dc29fdc3fbdc5930a10aba114050b82fe5a3e\",\n",
      "        \"title\": \"End-to-End Object Detection with Transformers\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"fb93ca1e004cbdcb93c8ffc57357189fa4eb6770\",\n",
      "        \"title\": \"ResNeSt: Split-Attention Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"0171ad4cc87cc7db25b4ec3169e293eed9a13b39\",\n",
      "        \"title\": \"Training with Quantization Noise for Extreme Model Compression\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"2709167f1c3a03fa5b970a665ea48ed243aab582\",\n",
      "        \"title\": \"Designing Network Design Spaces\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"b3e5bac38d098378ba24f826595b8ea877e342f6\",\n",
      "        \"title\": \"Circumventing Outliers of AutoAugment with Knowledge Distillation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a4ede8d8aa9482f316669c1fecd56c41e8da01de\",\n",
      "        \"title\": \"Fixing the train-test resolution discrepancy: FixEfficientNet\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"3c8a456509e6c0805354bd40a35e3f2dbf8069b1\",\n",
      "        \"title\": \"PyTorch: An Imperative Style, High-Performance Deep Learning Library\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"20ba55ee3229db5cb190a00e788c59f08d2a767d\",\n",
      "        \"title\": \"Self-Training With Noisy Student Improves ImageNet Classification\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"bb713d56a39a040b35e4f9e036fb4422f543e614\",\n",
      "        \"title\": \"On the Relationship between Self-Attention and Convolutional Layers\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"8de7f044a673d1f5e3b454d0663811f91aa9811a\",\n",
      "        \"title\": \"On the Efficacy of Knowledge Distillation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"87f6a7c014ce206ac5b57299c07e10667d194b39\",\n",
      "        \"title\": \"Randaugment: Practical automated data augmentation with a reduced search space\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"dfc7b58b67c31932b48586b3e23a43cc94695290\",\n",
      "        \"title\": \"UNITER: UNiversal Image-TExt Representation Learning\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1\",\n",
      "        \"title\": \"Reducing Transformer Depth on Demand with Structured Dropout\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"bf96f5c2d68f73d3f4d45603a5ccb803cdd92ea8\",\n",
      "        \"title\": \"Revisit Knowledge Distillation: a Teacher-free Framework\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\n",
      "        \"title\": \"VisualBERT: A Simple and Performant Baseline for Vision and Language\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\n",
      "        \"title\": \"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"c0aaee2337e5af680e5dca1bfc349a737dfec573\",\n",
      "        \"title\": \"Fixing the train-test resolution discrepancy\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"d6dccb5d71fbb6f5765f89633ba3a8e6809a720d\",\n",
      "        \"title\": \"Stand-Alone Self-Attention in Vision Models\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9\",\n",
      "        \"title\": \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"ed17929e66da7f8fbc3666bf5eb613d302ddde0c\",\n",
      "        \"title\": \"CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"27ac832ee83d8b5386917998a171a0257e2151e2\",\n",
      "        \"title\": \"Attention Augmented Convolutional Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"c41a11c0e9b8b92b4faaf97749841170b760760a\",\n",
      "        \"title\": \"VideoBERT: A Joint Model for Video and Language Representation Learning\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"fb8cf663a71bf31f59557a35d36aaf8c465b50af\",\n",
      "        \"title\": \"Selective Kernel Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1e7678467b1807777dcd9be557b79328ce9419a8\",\n",
      "        \"title\": \"MultiGrain: a unified image embedding for classes and instances\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"4e0bb8c1c683b43357c5d5216f6b74ff2cb32434\",\n",
      "        \"title\": \"Do ImageNet Classifiers Generalize to ImageNet?\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"29309743870c825f9645a4803af727402462e513\",\n",
      "        \"title\": \"Bag of Tricks for Image Classification with Convolutional Neural Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f723eb3e7159f07b97464c8d947d15e78612abe4\",\n",
      "        \"title\": \"AutoAugment: Learning Augmentation Policies from Data\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"d23a1cd6c73e3e43295c3585b3db147eb1c3ee91\",\n",
      "        \"title\": \"How to Start Training: The Effect of Initialization and Architecture\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"6a0aaefce8a27a8727d896fa444ba27558b2d381\",\n",
      "        \"title\": \"Relation Networks for Object Detection\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"8899094797e82c5c185a0893896320ef77f60e64\",\n",
      "        \"title\": \"Non-local Neural Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"45dfef0cc1ed96558c1c650432ce39d6a1050b6a\",\n",
      "        \"title\": \"Fixing Weight Decay Regularization in Adam\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"4feef0fd284feb1233399b400eb897f59ec92755\",\n",
      "        \"title\": \"mixup: Beyond Empirical Risk Minimization\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"fb37561499573109fc2cebb6a7b08f44917267dd\",\n",
      "        \"title\": \"Squeeze-and-Excitation Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"2788a2461ed0067e2f7aaa63c449a24a237ec341\",\n",
      "        \"title\": \"Random Erasing Data Augmentation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"8760bc7631c0cb04e7138254e9fd6451b7def8ca\",\n",
      "        \"title\": \"Revisiting Unreasonable Effectiveness of Data in Deep Learning Era\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\n",
      "        \"title\": \"Attention is All you Need\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\n",
      "        \"title\": \"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"43428880d75b3a14257c3ee9bda054e61eb869c0\",\n",
      "        \"title\": \"Convolutional Sequence to Sequence Learning\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"97fb4e3d45bb098e27e0071448b6152217bd35a5\",\n",
      "        \"title\": \"Layer Normalization\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"de5e7320729f5d3cbb6709eb6329ec41ace8c95d\",\n",
      "        \"title\": \"Gaussian Error Linear Units (GELUs)\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"51db1f3c8dfc7d4077da39c96bb90a6358128111\",\n",
      "        \"title\": \"Deep Networks with Stochastic Depth\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\n",
      "        \"title\": \"Deep Residual Learning for Image Recognition\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\n",
      "        \"title\": \"Rethinking the Inception Architecture for Computer Vision\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"0c908739fbff75f03469d13d4a1a07de3414ee19\",\n",
      "        \"title\": \"Distilling the Knowledge in a Neural Network\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"eb42cf88027de515750f230b23b1a057dc782108\",\n",
      "        \"title\": \"Very Deep Convolutional Networks for Large-Scale Image Recognition\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\n",
      "        \"title\": \"ImageNet Large Scale Visual Recognition Challenge\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a83cec6a91701bd8500f8c43ad731d4353c71d55\",\n",
      "        \"title\": \"3D Object Representations for Fine-Grained Categorization\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\n",
      "        \"title\": \"ImageNet classification with deep convolutional neural networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\n",
      "        \"title\": \"ImageNet: A large-scale hierarchical image database\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"02b28f3b71138a06e40dbd614abf8568420ae183\",\n",
      "        \"title\": \"Automated Flower Classification over a Large Number of Classes\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"Pytorch image models\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\n",
      "        \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"Edouard\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"The inaturalist challenge\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5d90f06bb70a0a3dced62413346235c02b1aa086\",\n",
      "        \"title\": \"Learning Multiple Layers of Features from Tiny Images\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"paperId\": \"2582ab7c70c9e7fcb84545944eba8f3a7f253248\",\n",
      "    \"references\": [\n",
      "      {\n",
      "        \"paperId\": \"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\n",
      "        \"title\": \"Distributed Representations of Words and Phrases and their Compositionality\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"834cb8e1e738b8d2c6d24e652ac966d6e7089a46\",\n",
      "        \"title\": \"Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"8007fc25a1f5c03f7c8ac95ccf5cf8aa3d989092\",\n",
      "        \"title\": \"Learning New Facts From Knowledge Bases With Neural Tensor Networks and Semantic Word Vectors\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82\",\n",
      "        \"title\": \"A semantic matching energy function for learning with multi-relational data\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"04cc04457e09e17897f9256c86b45b92d70a401f\",\n",
      "        \"title\": \"A latent factor model for highly multi-relational data\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5c12193fc84ed7973fe4515ae893625d8af4ce4f\",\n",
      "        \"title\": \"Max-Margin Nonparametric Latent Feature Models for Link Prediction\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"498ca0a1f8c980586408addf7ab2919ecdb7dd3d\",\n",
      "        \"title\": \"Factorizing YAGO: scalable machine learning for linked data\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1f4a4769e4d2fb846e59c2f185e0377190739f18\",\n",
      "        \"title\": \"Learning Structured Embeddings of Knowledge Bases\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f6764d853a14b0c34df1d2283e76277aead40fde\",\n",
      "        \"title\": \"A Three-Way Model for Collective Learning on Multi-Relational Data\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649\",\n",
      "        \"title\": \"Understanding the difficulty of training deep feedforward neural networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"81bbe42e3ec09c28b8864956148e58f4cb5aa860\",\n",
      "        \"title\": \"Modelling Relational Data using Bayesian Clustered Tensor Factorization\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"4e07791ee0872401215f12aefde342bd843240cc\",\n",
      "        \"title\": \"Nonparametric Latent Feature Models for Link Prediction\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"fec691d09b564986ad27162ce15344604c840ff9\",\n",
      "        \"title\": \"Relational learning via collective matrix factorization\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1976c9eeccc7115d18a04f1e7fb5145db6b96002\",\n",
      "        \"title\": \"Freebase: a collaboratively created graph database for structuring human knowledge\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"87ca5a0f345533c30217f6359bc4325a2442a0b9\",\n",
      "        \"title\": \"Learning Systems of Concepts with an Infinite Relational Model\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"68c03788224000794d5491ab459be0b2a2c38677\",\n",
      "        \"title\": \"WordNet: A Lexical Database for English\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"9157970408f931a45a7d245ac909ad7f1c2558bd\",\n",
      "        \"title\": \"PARAFAC: parallel factor analysis\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"HEAD AND LABEL) PREDICTED TAILS\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"paperId\": \"f4ba954b0412773d047dc41231c733de0c1f4926\",\n",
      "    \"references\": [\n",
      "      {\n",
      "        \"paperId\": \"3fab92869cfab684b3ffb1c16a771e9c3b774acd\",\n",
      "        \"title\": \"The Use of Classifiers in Sequential Inference\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"02c8a0bc8bab9920e6615cfacf1df2ab3f2b1f68\",\n",
      "        \"title\": \"Information Extraction with HMM Structures Learned by Stochastic Optimization\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"bece46ed303f8eaef2affae2cba4e0aef51fe636\",\n",
      "        \"title\": \"Maximum Entropy Markov Models for Information Extraction and Segmentation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"844db702be4bc149b06b822b47247e15f5894cc3\",\n",
      "        \"title\": \"Discriminative Reranking for Natural Language Parsing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f71c68f0c7a94851f06de396dff2e2588ad44768\",\n",
      "        \"title\": \"Proceedings of the Thirteenth Annual Conference on Computational Learning Theory\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1720d537c7378d0e9e37896fd01bd361a1b7f623\",\n",
      "        \"title\": \"Minimization algorithms for sequential transducers\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"084c55d6432265785e3ff86a2e900a49d501c00a\",\n",
      "        \"title\": \"Book Reviews: Foundations of Statistical Natural Language Processing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"3ed17a1114e2dc48597ab17cc8d5234006f525c9\",\n",
      "        \"title\": \"Learning to Resolve Natural Language Ambiguities: A Unified Approach\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"d30cf4154da4dc8c8073c2f59cc35b1e7d453a65\",\n",
      "        \"title\": \"Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f72084efcae8b2007e590b0c5a8f1decb61ef935\",\n",
      "        \"title\": \"A whole sentence maximum entropy language model\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"4ba566223e426677d12a9a18418c023a4deec77e\",\n",
      "        \"title\": \"A decision-theoretic generalization of on-line learning and an application to boosting\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f4cc5563c694355ddcf746ff9a55ccdb22d86a98\",\n",
      "        \"title\": \"Finite-State Transducers in Language and Speech Processing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"fb486e03369a64de2d5b0df86ec0a7b55d3907db\",\n",
      "        \"title\": \"A Maximum Entropy Approach to Natural Language Processing\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"2ffaf95de19deeacda2a9ea385adc0e4a3f95d3f\",\n",
      "        \"title\": \"Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"b951b9f78b98a186ba259027996a48e4189d37e5\",\n",
      "        \"title\": \"Inducing Features of Random Fields\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"307142db035938bef49b232e371238d895db4df2\",\n",
      "        \"title\": \"A comparison of several approximate algorithms for finding multiple (N-best) sentence hypotheses\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"37c931cbaa9217b829596dd196520a838562a109\",\n",
      "        \"title\": \"Generalized Iterative Scaling for Log-Linear Models\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"cb0690094be9d21334745f917b0adc4d87e0e898\",\n",
      "        \"title\": \"Efficient Training of Conditional Random Fields\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"9956f29b45ec60463511cb24bafdb2380e6b1aad\",\n",
      "        \"title\": \"An Introduction to Probabilistic Automata\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f42b865e20e61a954239f421b42007236e671f19\",\n",
      "        \"title\": \"GradientBased Learning Applied to Document Recognition\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"2000).Logistic regression,AdaBoost,andBregmandistances.Proc.13th COLT\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"5db4c0f527adc11923c97a05e947e21711572a97\",\n",
      "        \"title\": \"Boosting Applied to Tagging and PP Attachment\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"162d958ff885f1462aeda91cd72582323fd6a1f4\",\n",
      "        \"title\": \"Gradient-based learning applied to document recognition\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a574e320d899e7e82e341eb64baef7dfe8a24642\",\n",
      "        \"title\": \"A Maximum Entropy Model for Part-Of-Speech Tagging\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"b579e6516d9e27949b74d37e40f24c136aba9b0b\",\n",
      "        \"title\": \"Equivalence of Linear Boltzmann Chains and Hidden Markov Models\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"2dc4d6d7d55f9f0f1de53bb7f6816502f8f38892\",\n",
      "        \"title\": \"Boltzmann Chains and Hidden Markov Models\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": null,\n",
      "        \"title\": \"Une approche th\\u00b4eorique de l\\u2019apprentissage connexionniste: Applications `a la reconnaissance de la parole\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"ec75e3ca906681bd900218a348a4a35dfed3d6fd\",\n",
      "        \"title\": \"Markov fields on finite graphs and lattices\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a830f32fba171482ed9d187168fbf5b691524ab5\",\n",
      "        \"title\": \"Introduction to Probabilistic Automata\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor paper_id, sid in zip(df[\"paperId\"], df[\"sid\"]): \\n    url = \"https://api.semanticscholar.org/graph/v1/paper/\"+str(paper_id)+\"/references?limit=10\"\\n    response = requests.get(url, headers=headers).json()\\n    for line in response[\"data\"]:\\n        dic_cite.append({\"sid\":sid,\"citingPaperId\":line[\"citedPaper\"][\"paperId\"]})\\n        \\nprint(dic_cite)\\n\\n\\nfor id in ids: \\n    url = \"https://api.semanticscholar.org/graph/v1/\"+str(id)+\"/citations\"\\n    print(url)\\n\\n    response = requests.get(url, headers=headers).json()\\n    print(json.dumps(response, indent=2))\\n# Save the results to json file\\n\\nwith open(output_file, \"w\", newline=\\'\\', encoding=\"utf-8\") as outfile  :   \\n    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"authorId\", \"url\", \"name\", \"paperCount\", \"hIndex\"])\\n\\n    # Write the headers to the CSV files\\n    csv_writer_1.writeheader()\\n    for line in response:\\n        count+=1\\n        try:  \\n            row_papers = {\\n                        \"sid\": count, # Add a new column with a surrogated ID, just in case\\n                        \"authorId\": line.get(\"authorId\"),\\n                        \"url\": line.get(\"url\"),\\n                        \"name\": line.get(\"name\"),\\n                        \"paperCount\": line.get(\"paperCount\"),\\n                        \"hIndex\": line.get(\"hIndex\")\\n                        }\\n            # Write the row to CSV 1\\n            csv_writer_1.writerow(row_papers)\\n        except json.JSONDecodeError as e:\\n            print(f\"Error decoding JSON: {e}\")\\nprint(f\"Modified JSONL saved to {output_file}\")\\n'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file=\"csv/citations.csv\"\n",
    "papers_file = \"csv/papers.csv\"  \n",
    "\n",
    "df=pd.read_csv(papers_file)\n",
    "dic_cite=[]\n",
    "\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "ids=df[\"paperId\"][0:3].tolist()\n",
    "\n",
    "\n",
    "r = requests.post(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "    params={'fields': 'references'},\n",
    "    json={\"ids\": ids}\n",
    ")\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))\n",
    "\n",
    "\"\"\"\n",
    "for paper_id, sid in zip(df[\"paperId\"], df[\"sid\"]): \n",
    "    url = \"https://api.semanticscholar.org/graph/v1/paper/\"+str(paper_id)+\"/references?limit=10\"\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "    for line in response[\"data\"]:\n",
    "        dic_cite.append({\"sid\":sid,\"citingPaperId\":line[\"citedPaper\"][\"paperId\"]})\n",
    "        \n",
    "print(dic_cite)\n",
    "\n",
    "\n",
    "for id in ids: \n",
    "    url = \"https://api.semanticscholar.org/graph/v1/\"+str(id)+\"/citations\"\n",
    "    print(url)\n",
    "\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "    print(json.dumps(response, indent=2))\n",
    "# Save the results to json file\n",
    "\n",
    "with open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile  :   \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"authorId\", \"url\", \"name\", \"paperCount\", \"hIndex\"])\n",
    "\n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    for line in response:\n",
    "        count+=1\n",
    "        try:  \n",
    "            row_papers = {\n",
    "                        \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                        \"authorId\": line.get(\"authorId\"),\n",
    "                        \"url\": line.get(\"url\"),\n",
    "                        \"name\": line.get(\"name\"),\n",
    "                        \"paperCount\": line.get(\"paperCount\"),\n",
    "                        \"hIndex\": line.get(\"hIndex\")\n",
    "                        }\n",
    "            # Write the row to CSV 1\n",
    "            csv_writer_1.writerow(row_papers)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "print(f\"Modified JSONL saved to {output_file}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified JSONL saved to csv/authors.csv\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.semanticscholar.org/graph/v1/author/batch\"\n",
    "output_file=\"csv/authors.csv\"\n",
    "papers_file = \"csv/papers.csv\" \n",
    "count=0  \n",
    "query_params = {\n",
    "    \"fields\": \"name,url,paperCount,hIndex\"#,papers\"\n",
    "}\n",
    "\n",
    "df=pd.read_csv(papers_file)\n",
    "ids=df[\"authorId\"].values.tolist()\n",
    "\n",
    "data = {\n",
    "    \"ids\": ids\n",
    "}\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "# Send the API request\n",
    "response = requests.post(url, params=query_params, json=data, headers=headers).json()\n",
    "# Save the results to json file\n",
    "with open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile  :   \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"authorId\", \"url\", \"name\", \"paperCount\", \"hIndex\"])\n",
    "\n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    for line in response:\n",
    "        count+=1\n",
    "        try:  \n",
    "            row_papers = {\n",
    "                        \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                        \"authorId\": line.get(\"authorId\"),\n",
    "                        \"url\": line.get(\"url\"),\n",
    "                        \"name\": line.get(\"name\"),\n",
    "                        \"paperCount\": line.get(\"paperCount\"),\n",
    "                        \"hIndex\": line.get(\"hIndex\")\n",
    "                        }\n",
    "            # Write the row to CSV 1\n",
    "            csv_writer_1.writerow(row_papers)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "print(f\"Modified JSONL saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import re\n",
<<<<<<< HEAD
    "import pandas as pd\n",
    "import urllib.parse"
=======
    "from time import sleep\n",
    "\n",
    "load_dotenv()"
>>>>>>> 7306732bf11aa73b3a1303524405ca1494b496cc
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the databases of the API with the following code. We will be using the oldest version of the databases."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 3,
>>>>>>> 7306732bf11aa73b3a1303524405ca1494b496cc
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"release_id\": \"2022-05-10\",\n",
      "  \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThese datasets provide a variety of information about research papers taken from a snapshot in time of the Semantic Scholar corpus.\\n\\nThis site is provided by The Allen Institute for Artificial Intelligence (\\u201cAI2\\u201d) as a service to the\\nresearch community. The site is covered by AI2 Terms of Use and Privacy Policy. AI2 does not claim\\nownership of any materials on this site unless specifically identified. AI2 does not exercise editorial\\ncontrol over the contents of this site. AI2 respects the intellectual property rights of others. If\\nyou believe your copyright or trademark is being infringed by something on this site, please follow\\nthe \\\"DMCA Notice\\\" process set out in the Terms of Use (https://allenai.org/terms).\\n\\nSAMPLE DATA ACCESS\\nSample data files can be downloaded with the following UNIX command:\\n\\nfor f in $(curl https://s3-us-west-2.amazonaws.com/ai2-s2ag/samples/MANIFEST.txt)\\n  do curl --create-dirs \\\"https://s3-us-west-2.amazonaws.com/ai2-s2ag/$f\\\" -o $f\\ndone\\n\\nFULL DATA ACCESS\\nDownloading the full data requires an API key, which can be obtained at https://www.semanticscholar.org/product/api#Partner-Form\\nFor access to the full datasets, see https://api.semanticscholar.org/api-docs/datasets.\\n\\nLICENSE and ATTRIBUTION\\n\\nSee the README files for each dataset for information about licensing and attribution.\",\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"name\": \"abstracts\",\n",
      "      \"description\": \"Paper abstract text, where available.\\n100M records in 30 1.8GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"abstracts\\\" dataset provides abstract text for selected papers.\\n\\nSCHEMA\\n - openAccessInfo\\n   - externalIds: IDs of this paper in different catalogs\\n   - license/url/status: open-access information provided by Unpaywall, linked by DOI or PubMed Central ID\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"authors\",\n",
      "      \"description\": \"The core attributes of an author (name, affiliation, paper count, etc.). Authors have an \\\"authorId\\\" field, which can be joined to the \\\"authorId\\\" field of the members of a paper's \\\"authors\\\" field.\\n75M records in 30 100MB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"authors\\\" dataset provides summary information about authors.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Author-Data\\n\\nThis dataset does not contain information about an author's papers.\\nInstead, join with authors.authorId from the \\\"papers\\\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"citations\",\n",
      "      \"description\": \"Instances where the bibliography of one paper (the \\\"citingPaper\\\") mentions another paper (the \\\"citedPaper\\\"), where both papers are identified by the \\\"paperId\\\" field. Citations have attributes of their own, (influential classification, intent classification, and citation context).\\n2.4B records in 30 8.5GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"citations\\\" dataset provides details about one paper's citation of another paper.\\n\\nSCHEMA\\n - isinfluential: true/false if the citation is considered influential. https://www.semanticscholar.org/faq#influential-citations\\n - contexts: Text surrounding the citation in the source paper's body.\\n - intents: Classification of the intent behind the citations. https://www.semanticscholar.org/faq#citation-intent\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\\n@inproceedings{cohan-etal-2019-structural,\\n    title = \\\"Structural Scaffolds for Citation Intent Classification in Scientific Publications\\\",\\n    author = \\\"Cohan, Arman  and\\n      Ammar, Waleed  and\\n      van Zuylen, Madeleine  and\\n      Cady, Field\\\",\\n    booktitle = \\\"NAACL\\\",\\n    year = \\\"2019\\\",\\n    url = \\\"https://aclanthology.org/N19-1361\\\",\\n    doi = \\\"10.18653/v1/N19-1361\\\"\\n}\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"embeddings\",\n",
      "      \"description\": \"A dense vector embedding representing the contents of the paper.\\n120M records in 30 28GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"embeddings\\\" dataset provides embeddings representing a paper's contents in vector form.\\n\\nThe model is based on the SPECTER model available at https://github.com/allenai/specter. However, the embeddings\\nincluded in this dataset are not compatible with the embeddings produced by the pretrained model from that repo.\\n\\nLICENSE\\nThis software is released under the Apache 2.0 license. (https://www.apache.org/licenses/LICENSE-2.0)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{specter2020cohan,\\n  title={{SPECTER: Document-level Representation Learning using Citation-informed Transformers}},\\n  author={Arman Cohan and Sergey Feldman and Iz Beltagy and Doug Downey and Daniel S. Weld},\\n  booktitle={ACL},\\n  year={2020}\\n}\\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"papers\",\n",
      "      \"description\": \"The core attributes of a paper (title, authors, date, etc.).\\n200M records in 30 1.5GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"papers\\\" dataset provides core metadata about papers.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data\\n\\nThis dataset does not contain information about a paper's references or citations.\\nInstead, join with citingPaperId/citedPaperId from the \\\"citations\\\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{Ammar2018ConstructionOT,\\n  title={Construction of the Literature Graph in Semantic Scholar},\\n  author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu A. Ha and Rodney Michael Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler C. Murray and Hsu-Han Ooi and Matthew E. Peters and Joanna L. Power and Sam Skjonsberg and Lucy Lu Wang and Christopher Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},\\n  booktitle={NAACL},\\n  year={2018}\\n}\\n\\n\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"s2orc\",\n",
      "      \"description\": \"Full-body paper text parsed from open-access PDFs. Identifies structural elements such as paragraphs, sections, and bibliography entries.\\n35M records in 30 3GB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"s2orc\\\" dataset contains parsed full-body text from selected papers.\\n\\nA subset of this data was previously released (in a different format) as S2ORC https://github.com/allenai/s2orc\\n\\nThe body text is parsed from PDF documents using Grobid, documented at https://grobid.readthedocs.io.\\nIts output is converted from XML into a single string with a set of annotation spans.\\n\\nSCHEMA\\n - externalIds: IDs of this paper in different catalogs\\n - content:\\n   - source:\\n\\t   - pdfUrls: URLs to the PDF\\n\\t   - oaInfo: license/url/status information from Unpaywall\\n   - text: Full body text as a single string\\n   - annotations: Annotated spans of the full body text\\n\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\n@inproceedings{lo-wang-2020-s2orc,\\n    title = \\\"{S}2{ORC}: The Semantic Scholar Open Research Corpus\\\",\\n    author = \\\"Lo, Kyle  and Wang, Lucy Lu  and Neumann, Mark  and Kinney, Rodney  and Weld, Daniel\\\",\\n    booktitle = \\\"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\\\",\\n    month = jul,\\n    year = \\\"2020\\\",\\n    address = \\\"Online\\\",\\n    publisher = \\\"Association for Computational Linguistics\\\",\\n    url = \\\"https://www.aclweb.org/anthology/2020.acl-main.447\\\",\\n    doi = \\\"10.18653/v1/2020.acl-main.447\\\",\\n    pages = \\\"4969--4983\\\"\\n}\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"tldrs\",\n",
      "      \"description\": \"A short natural-language summary of the contents of a paper.\\n58M records in 30 200MB files.\",\n",
      "      \"README\": \"Semantic Scholar Academic Graph Datasets\\n\\nThe \\\"tldrs\\\" dataset provides short natural-language summaries of a paper's content.\\n\\nThe model is based on the SciTLDR model available at https://github.com/allenai/scitldr.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@article{cachola2020tldr,\\n  title={{TLDR}: Extreme Summarization of Scientific Documents},\\n  author={Isabel Cachola and Kyle Lo and Arman Cohan and Daniel S. Weld},\\n  journal={arXiv:2004.15011},\\n  year={2020},\\n}\\n\\n\\n\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://api.semanticscholar.org/datasets/v1/release/\"\n",
    "\n",
    "# Set the release id we will work with the first release\n",
    "release_id = \"2022-05-10\"\n",
    "\n",
    "# Make a request to get datasets available the latest release\n",
    "response = requests.get(base_url + release_id)\n",
    "\n",
    "# Print the response data\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "res=json.loads(response.text)[\"datasets\"]\n",
    "dbs = []\n",
    "for dataset in res:\n",
    "    dbs.append(dataset[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstracts', 'authors', 'citations', 'embeddings', 'papers', 's2orc', 'tldrs']\n"
     ]
    }
   ],
   "source": [
    "print(dbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each database is really big and because of that it is divided different downloadable parts. Let's list the first link of each part, click on it to download it."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 8,
>>>>>>> 7306732bf11aa73b3a1303524405ca1494b496cc
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstracts download url:\n",
<<<<<<< HEAD
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/abstracts/20220513_070629_00025_mtwkq_0b601c4a-dca2-4eab-921b-1c86bcba0147.gz?AWSAccessKeyId=ASIA5BJLZJPWV4IQXRFZ&Signature=ub6RkmV1DIeT7YctnfZDpGKeMT0%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEMv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIH8fAKDF0J3RAmWi%2FFCeSg0zCX1ETGWnHOZ%2BgDTgeWyqAiEA0EvDToJJR2uICdIfo5gc7yScXg%2FyCPi%2Bz3UUeRqCWjwq%2FwMIFBAAGgw4OTYxMjkzODc1MDEiDA9dRDpcG%2FWDtnl1eircA4KFxd3%2BpoQ2jl1Im2eQPtyq20ixJx6kOw1e3lnwU1nSHG0vkIz3TTrSrFfAlW01B%2B82PKmPjARceLzCRIdH811%2FI2STtNiTopP4A02LpSiq1zW4M1OlbHtXq8QknsyKPkWehzPjQHoNSa%2FjPSGC2ymBnZqmC6mIQREln2iXnnoN9qUWvBQIJ03Gvs%2FBJrg1kYciuChnXQqxpVyHGjP%2FkXOBZvW%2FsPHP5q1gB2UOcPvYRMVe2ABF5Tn%2Fiw59Z231aEuH3MjcH5UvWGc4Hy9JF2eqpde7b49dOeHTDDdyFDch28OqMbVg%2BP7m6HYPt%2BZv8u9dgZA%2FflQWmqBGpbzLZD8HH%2FLskBNSvAy5SfxkpF%2BNdx5PvDBUP2ehJBdALxhHq%2BrdE35URlXU8XM8Mga1kogILTRJtqrqo6MozfcFMZvQoVet0WQ%2FlOtHyG2GpthLQ9L4NxMyLZblzj7DSnL8z%2FqGUjicdCMxN9MRyo1Jh8AzQiqzO3uTBRAwzIft4EHuGkgW5TsAVRpzbwEwaVUprCZy3cmdLhtXZ2M8NVc3t3AznwWruE%2B2ifd3BmwCouP6KiJE%2FR8pgjw2NQ9fYT6PqnIn69LTeD42y5dTyKB5AfFlxJQjhhKIWsx%2BzSABMJLPoL4GOqUBM9PKg9rEUdwZRwihppTdcKKcqCPzq7uf6%2FQ3MImwi7uXbmgNZTgKVBgaqUNfE%2B3okD1QdTnP%2BWZMuOJP71QpZh9VLZc9hM9kgdaQHEcv8W0vPUtUicY8DugL4xfTYHR3dNdcfyfZBXovAJ3PAU4LOziSMWhYCr0ixg6zfOy6ir4vdjXhhKgda2cu4R3UkJRA9XItL5QsLkgs9PyEXNKMgPl66cAz&Expires=1741790317\n",
      "authors download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/authors/20220513_071222_00034_g4b97_046945fe-8bc5-4e7b-8bca-95cc504838e8.gz?AWSAccessKeyId=ASIA5BJLZJPWXYEBHI72&Signature=wJiCUnQh2Eoa0HzLs1%2BTpa9XtgM%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQD0ArBpN8GVvDeZKUHnz%2BGc1%2B4yLlSmy5eoGEFsh1euwQIgY0cq78Z4BeZQ0Cy1XIAOlVW%2B0%2BrEu3KldhMJ43W9hZIq%2FwMIFxAAGgw4OTYxMjkzODc1MDEiDDmPSj7otk3TV8gRUyrcA7mLfifxs%2BHoXQxKXh3DmHlXj8AfLGRrX55jZOotTBZYAkPffYnGHVCr8TFN2wW1iHdYlrkeXah8yrFBthkVV9I8qYFpizsYng2ngjew6AwfOHuqVlNpNPjDAFt48%2BC7wf4oLa4hUWUKJx59ob3vn8%2FDjdjve0S%2FWE9W1PY75qMCqdOpk%2B7VKDgY5wyG40%2FglP3xYdOXMUI7HgejKJ%2BhdmkjgFY3vPMRTbvHGVmEvkE9%2BjcT8hp9p1cL%2BOplQbt%2F%2F1YgHrKwNOOSYOSz8EF42bBanMBQXu7TQMQf09xQHg0tHCZbE%2Bk1pl01FA8G9b1VQZ48CGglJ2bg%2FzpIliTUPf7%2B5PEpaNMhCvpXmWls%2FgeassL%2FcPhWHVunKpOlVGhw9LBaEyqg%2BlgpXhCaNyviGnjNAGaJbWXxM3RIrFvEWJfBb1emvrh3NmHvTnIME6na1cmPc1geoquUOOmFh20FCSCReBsRTg%2F5JmAaugbeweKWelHu%2FjLRv6M1A32y0fo7iLaNXJdMFxCq2QmdieyPrMomTEV5YUwZfbdS6LdCUmA8Z%2Blfxa3X%2B5Ne1Md09uK8sGHjvJBEM9vVwPknAlUDOXil%2FL4O2sYrqxp9N8Ern41zn8Zp2QI%2B1FRAneOoMKiiob4GOqUBPj0AvHMXk%2B%2F2hjvJNCgW7MT8sgsZdxgmbRCTYX7xVai81mEGBIAMegoipkybdnHVCjqa41ImAYnCn1NkHFVtbw24TJVT0wMi2QeOozLQ%2Bao1GkBSPM9v68GTeVaEnV5LTYP6Mu3iP1Lsm%2BqN6dwUIYEUgr4p2PE%2FCiwi6xwen3%2FstH2Weoo%2BxMr2Kd7ThWXlSNYf7mdcBbDJYCqn6C6eawnE0A7t&Expires=1741790318\n",
      "citations download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/citations/20220513_071330_00037_xkiix_00bc87b3-00b5-4912-91e0-2e7ea0a433a0.gz?AWSAccessKeyId=ASIA5BJLZJPWXRBQBYVN&Signature=bS%2FIs%2Ba77hJ5JXXwdjJ2ft3dKQM%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEMz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDreoiBpwkZv63mDlR1rdTPPsQ2U1gS55HrlTtcGLFcMgIgaWEazsatwlCDoN4LWL2Cr80hmf34E8h92tXHYIaKWxQq%2FwMIFRAAGgw4OTYxMjkzODc1MDEiDJBAP4ouRyJwwcUANircA0WIziDmeyGupH3UOa5LEiOk53qlKXMY8VFyhB5yIXw8FnIxSMwtKPTHXnwssXXEUq6yItOlbNAHXFKAU6CKyflmoJwtPmLfpN%2FO1PZcbefLtV6w%2F0aTsShM7IxJ%2BoB6fNFy4FfEaUvB%2FHj3GMFapY4r3PzivhwT%2Fn0ACvhRfqN%2B0v99R6fF6oYQXmCRN6c%2FHzwuimnee1BAJwP6RELOMTLuAjTrdWzJWDS31Cm9%2FqgwJov9dS9GY6gLVoM9ppxkmSM2EHQDP82gX7TSW2EpS%2Fan1ZvlDgBoypDzAmzF6pjuB7aCJAHW6LI%2F%2FRLDt9uHsHJdfJLUNwVzhnLgc5GAY6Qis8MPo38xpsW%2B1LVLsK0GlnR4sXWoUs%2BmFuLZ3jK52EnEquDPJ78QWwSSDqhEIYfGZhXfHLsIlUDVL4lW19%2FDignDk9m4Fj%2F198ZXUYGIFvQfFsz1bfDCmB0HrmyaoK7kA0O9ZctrmjyASXwORwOx0ZIBkFxdgM6%2Fjp8lNURUcireo1orUnDQR6GjG368bKiU%2BvhhgPNiWqlxw7ibbyATiy4BoygkD2ZHbBvJO%2Fx2NPC%2FcGxOPHCSGOnqrkPmg7Yz%2Bs5KX%2BZOSTytGHKVy%2BCTbFtEURsSAvmVR3qrMPf2oL4GOqUB5QPSNpo9If7G3o6HhlhXwSFYQh27eMDMAW4eZPRHyTZV8oQpMOEpIdqc82bIVlRougnjLo0JLPRXmxGaT4MGV98PqjaT%2BYurJrN%2BUnLLR8ti1UJdBqy%2FTj5CMQvqgBC2boXeuWm09puPG9eF9GCZ15EZShG0p7vhWiyf0Hs0dqAWIebEj%2FfhHX%2BYa0ipqIkEazEDzBKoYL%2BpHQIg9sz%2F65RUgDt8&Expires=1741790320\n",
      "embeddings download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/embeddings/20220513_073500_00025_jcu4c_08b8baf2-dfe2-4d95-804a-01e951f4b532.gz?AWSAccessKeyId=ASIA5BJLZJPWWX7UMFOX&Signature=CkL6sKQTCZ8w%2F%2FYuviZ32EB3aMk%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCodCsH1RuiaFsLM%2BylH%2FpECT6kTIGaotTw%2BJ%2FkOgrmFAIhAOS1XRs5RyK9jmDflAX8IoIiPDsUosZu8NyYj7u3c7GDKv8DCBcQABoMODk2MTI5Mzg3NTAxIgxasMfYxTqDawrtAO0q3AOUfAjEyiX8aNyRjU8MlMpSahi6X%2FwcabH8KvNBvUBFaQsD2b%2BT48AKBSm67dcRYRVeyPCe2qLIn6uU3PasyjS9sLBakBeftGo%2BEH2y5XsXdjUv7fcImPV8lkR9MlP7SR0dzPk6l6KH9k4oHQq1iM%2Fv2uXkerT%2FH%2FxwEo%2FBsvK3nWwVoGtC%2BL18pQVNR6ijiEHG%2BH%2Fhy8VpjYdQEUc43BFgfgeX7bdd5nL4KwXSKBUmkUFvewZXSRk2%2Bz4e%2FOqZAb5uAFCAC%2BdqKehlfwHOC1U1nK4jAHgAxXBe6icGa%2B8llCOOth5YiT3bQDPUpVOm3rsZrkfGbgmpV4kwh%2BxGcdIoweo7v5jC2k51P9Kjpb2lI3OST39zd3jsMZVRFWZ7r8x8fPSWsMCEKyrS8wvSrsBC%2FxROmCBYLKjxuMmTd8POvjSUkzQJS7nJOe%2FWz6XWrONmy%2BaUdq1A8p4h9FauDDgdQCI50zGgxwfJ9gzgt2yWz%2FIJ1BbrIy93S%2Fiow74sjTWPOMiD%2B9h4oK9oXIhTScmoj4Oz%2BBGrqLrPsnpIp2JjOvpqWs%2Bd0L4kkveaeOYDUaSOsoDMLp6zdCrQmL3hQRoLe3KBExLu66voK9McVjSKmTy%2F5PFydKbIjRw7STDurKG%2BBjqkAQkMUXNc3Y3JqHxOrPzQvSMMZ26LCj7GfNs00dxd%2FiqMY88mkDfrRblJSD%2BHgwC6tyeV8PmcSyUw%2FVp43qJ4RjbKWlr7lSqC5e5ZN8PFV2pb%2BGzTSShDDH6KFvL4%2BDDd9akPFXQcEcLHelhrlamKSCmbV3OJtR9v2uG2gbLF5QA2vT6qho7UAeVPU9aqciDFq75x6xSL17uvaKC8qA7KXi0Bf3YA&Expires=1741790321\n",
      "papers download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/papers/20220513_070151_00012_4bpee_054cd248-48ad-47d6-b0d9-e4fe4333cc61.gz?AWSAccessKeyId=ASIA5BJLZJPWRCVT7POI&Signature=odFWgPm9tQd1gjGqCUFGZk%2Bra%2BE%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEMz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIBmS%2FfT4zgQo2oeRv60nFL0TsAi88zT%2BF3L2OPGuFIbEAiEAwIet41mtyFlTR16dOdJxzrZRKRnhce3jlk7r8r1yP7Uq%2FwMIFRAAGgw4OTYxMjkzODc1MDEiDAWVmhIW0KBE2BsDtyrcAwVIHWR9EZz7M%2BcWc4YpNU2PI3Q8fIeV7sSe0Heh5uf64qsbke0R1Q0p5Ifp2BKt7jCTgBQcu2Tfy46Sp54okum83GEbUnuiLGAPJhvG%2FribSjtNKa3pG1m4TJiBs04WO8BMVBRr6jc8iuGcQ%2B9nOynRNL%2FVu0IUQjoUbMWkhicruF1BzXsLpv8cnVR8DXE04Xpj%2B%2Fen3FcTmNwPeb9WvyT6Zmz91r3GfzjJqhBAFKF%2BhWZoffQwCzIJq%2FpKERXH0zaeuuSDu7hkI8GYSbyN27QLTcpYnigEXwqQiK7Nf5aoz%2BrLBBqd6Wzeu5Owj1nPg7Hr53RDCi2qkbEqVChb9LN1TTHYt4grWzm2jgW%2BhOWVWTW%2BoJSx2HYI7kclmuQAT58gyRUoL03Uh0ykjZugOoTQsiJKad5HW2GupVRFb3qKRtXhYKWx0vSiOFclbkGEixfTVpHck0%2BE%2BBFcPlzplUdA83qCCL16T48UYCxiUtcFBVpRG%2FSiHOdx0pXL%2BN5oQ8NxxgEgkeTawZjpx1eghqM6GW4XJK%2FmmT3j%2BPGGH%2Bm5RydRYm2LF6ubLh0MJfDVyqCXEo7qvX%2BT8QHRte0l58of2gmJj4qX5NmdVbBM8cGp%2BkOY03T9vUFpZyQzMOrtoL4GOqUBXCTioy7TGjhSxkrK9K6jaGMwZzNNDZ2msYPPtxyyMJw3bwVAL0xdgt3LBTMGe9YhrnBHmPxORUm5sklH8xY4oDh186426d4wEwubihurIcdCRfPFsNBxYBo%2FWds4IWaivtaKvZIeBZyrVoOTuJBpEdZWxCn1eNgAKjfvrR7cVHnQ2R7K7jPn%2FDZTvq7NWgcU2AJ2%2FFRum6SXXEOLs%2Bn7r8shk3gN&Expires=1741790322\n",
      "s2orc download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/s2orc/20220519_000932_00025_dauyy_04c9ef07-dd83-42f4-b36a-4d3ea06c99b0.gz?AWSAccessKeyId=ASIA5BJLZJPWSRMIY22M&Signature=dTLx7VN9FNnJFMUN78203i19izo%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEMz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJGMEQCIH3CoGeeaIJBMSSQYS05ZVEHXIbjtRSssis6WqL2G%2BG3AiBGUbdLOzlESQpfOzczEmGYozYLH%2BYfmCmF%2FkIS7C2Njyr%2FAwgVEAAaDDg5NjEyOTM4NzUwMSIMZqjWl8naLR7L8PWrKtwDtojsgP3MCxB2IBriHgX1F8yM87l6Lq9SoYHKiiHvJMEwLJzHzei%2FmDkXXL%2Fxm3fnjQ7u9LxGD%2F7cpU3CmrjGfYPPhFza2gy8dLs5YcHfUBovKb3cbO7sO6hkkAbDmlJnFYezqPcLYHNtPAPJZaj6jOLpEgl9r%2F7tgPDjRQ6MxVfG53iLHOdKLX0pki%2FMJaJ%2BGEXK8vMKnywyhAZcRWeYPuZiR4EXtHzRvI7AS4rd2mhfzL2dirajeJZipEcfQ3N6r2r29cyH1jdSrnw65h5NnoW4IYfE5JzXDL5IM19l9LywkSv94Wh9disDMZuxJM4TzYqoTuzitcDTkh7T63e2H4N%2Fb8uclTp3IPPOraTvH%2FCqBeGpVCdVgQ1CbYxxuapE%2Fv3sMMThRfYXTZUNFEr2iVQQ0WoO7jikhDpyZeG3ARE6ZNxwKck4gB43ZEIWRTYyZg8V2IV1RSz59Qi4PmioTXvfKwu32yR2hlW5kwE9Yd1U4vtO8SyOXukMpaZhZ3Mvpesgz7GAMtmcS%2FabofaMMH0bIX%2BigpHBlPM174EtjhGb%2F7i9J95gNk%2Bei2aAug5L6TUVRgYW9yk%2FRMv3VeCH55YRJ%2FiICK%2F7CQwRC1PZKwISRdPzcpnTAhll3o0w5vugvgY6pgG3TV3FyLYDYGt2jNd5NhpiEy280cZ06JadKWE45ZuVYvs2surrkSIgCp%2B0vFIS%2BZs9%2Bi7yxW0SX0r%2Bx0yqW5y6zTNDSgJRSokzknh1%2Bz3kHiYsOxaVNjAqasa2Eu5uiSuPu9ie5dMg1hCo2Ohxs%2B3WbbYTs%2ByuiQvfgZsh%2FTRYZX9uyCP5hRyJycn%2FGmDmIRGd3nHCT%2BC%2BMlsnWMeJzKhL0SxQPCgU&Expires=1741790323\n",
      "tldrs download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/tldrs/20220513_073419_00109_m3j5m_02586bff-4a75-46c4-8f1f-e2d8ad0bbf75.gz?AWSAccessKeyId=ASIA5BJLZJPWQH7YB6SZ&Signature=ygGg3lDR7hgkSBXpwYmnr%2F1T97c%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEM3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCICcmlNYU8AmokiDwy4dQpdLUxiwuNEo%2BlvVwEgdKhFa%2BAiEAl7fFZSw86JE0YKiORVFmH6lHtLJGmHlxccVIuzX%2F1Ocq%2FwMIFhAAGgw4OTYxMjkzODc1MDEiDKlQJf%2BsK%2FYkvUKqAyrcA83EEJQeZ%2FOZtv2C%2BAxfYw8l1SgexlDsK5LJQmCc3Yll5mEO7KHIxA%2B89uzH8QrFZQnA%2FSP0VLm1nfD39WY18fNCN68%2BopRjZkVMoqLca82Jgww5821QSgDhMIY9fRnTp%2FQirnQxd0IVzFtrojHgsFADlydytZ9LjDwOYXTw6q7zY0FFXQRTn%2FGAOYvpM%2BHiO2LPh9J22ycDCay%2Fi%2FCODxVF0KCjOsl0jPfa4XXmGfwwO26Jyqslfuo7yW58kdjq3wyFBG3heiAKwQyO9sxQYmpkioputPUfaK8FfngkBcMAnmHJPT8ey9A%2BXGcHRiSUcZMH%2BPRkcoLElKRaTUQdu6cCAu%2FX6nATc2GDcDxAbhwHQh2Dvm7wo2fhpPjWyvEPGZhNVPdaOd9QM1x%2BcxPk2au9TJGuj2HqZduBiaoygHT3hVQ%2FtbvmBWLNawaaD9YZkfm9weUzFzm4DYBpnVdHvgnWX9368RLv6k2XGEQT%2FT2MNJbxdPm5Z0sA1g8gdsAVTM9zmBw%2FPylyJePw5AuPnBHjC5lMGB9WlXOWZhChOZS5FE%2BYDi1v6cpkSrFmhmySv8gE2O8DRB%2BI6hRUhPB9XqeEpby82AB6wkoJum3jmRQpVuaNA5%2FPZMHSoDTJMMmFob4GOqUBPOCyY7Fw%2B4k98p89zJvAl%2BIKRKW5nnTBHqjGqgtsSBOEv%2FJy1y4O83kbzBSx0anAf4px6aPhxU3J%2BA0aR5omnXjrhB%2BMp1d5R8Cjw%2BVzsWfitEnmmz3YCz12BZ%2Fd9aBwevyCrdyhmc4o7JAPzkcGBobJyIXi4u83eIWl%2FCjzN4SjAis6uE92GL8krdayydVmvvzaWSpEJW%2BC9XqoXHNiSZUsqNx8&Expires=1741790324\n"
=======
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/abstracts/20220513_070629_00025_mtwkq_0b601c4a-dca2-4eab-921b-1c86bcba0147.gz?AWSAccessKeyId=ASIA5BJLZJPW7Z77QZKE&Signature=qWAs82Go2FzDcl%2F%2FYHQ%2FPooCUZo%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDmIUwh%2BrWCKDivZkQpX4g%2F4RpGGhC00WEo5WBU97rs5gIgN6rrh9112bHH%2FelAxkJK0%2BTrf8nYlqz3PeqgFqqYDpIqiAQI7f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDEHK6Tmm3OMhu0BfwyrcA%2F6eyjpf463eYd%2FAf%2F45o2HcRsG4dZ8H%2BcB8Y5TYMKTcmEdFxGioGROea3hzYuy%2FvoIDtQMcu2igyw5gRI6kZMtBLtyVIUYG109IFEg9L1Sn92CO7foBGhNdN2aQZj40O7TfKIK3rLGHW6K%2Fs2ZEoRa%2FfNP25YkADBY%2FGnE6E6pNMDQ7Cxyn0Zz7FWUNPTzZp%2BWCrQa0gBgQl3eAIIFMO6Vn55BHQ7noQMAhCBIyoe42PlcG%2F%2F5RqFDFIlg2Jrshu3V0paDhDuk3YFnXllNRvjpmyjtriqJh7IN8ldakqmgZOOSUGa2z3scLoh3yirDmE3JuatLGNrXyTFdeFAjju8djWx5o5An8%2FOTaGSKTkhkNuunFu3waaFwNRkrSFXOOO6xd%2F74laim70m4EXpnu0bKVfp1WxTvBT6rCnE4xaB5ZOrXjwfTy7xcjqc7nEhif1pYb5QVveROFdNzWUWQ4d%2BgQ%2Fo8M6zSJ2Z7VDu7%2FU2SBdSONEz%2FBj7Nq6JaGHrk%2FhOpo%2F%2B7AXv4niy3loxD2j9WASwnoGLl13g%2BePcNna1dmLPsHXnrWyyGPnUdN4KeJ3oVWFeHlrNARgqxVDZ%2Bdig2wyZZFP0Rs806DM9ub1w2vUBCIJ5eFNuixP9bZMPnHm74GOqUBBAx444repdG4hjnQUdhZtM7dIaF3nXiwMeukBAX26lku8PC5bWAJbLwPHfUSqMs4j1K%2B2L4%2BfYEXRUIE720ug8ke06GNSI%2Bq1DQaIaATPun0xe6Nk1NKNH4fvbJkpcQSfBT9%2F0SZfPwBxGMyBc23%2BiSIGqQREVKlRATCNfq5HbLJPKCGv1sw5%2BOgV3JTQj%2Bvh34eT8JYCClnkbh6RJ%2F0x5LkaI6W&Expires=1741702135\n",
      "authors download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/authors/20220513_071222_00034_g4b97_046945fe-8bc5-4e7b-8bca-95cc504838e8.gz?AWSAccessKeyId=ASIA5BJLZJPWUPK3OYP7&Signature=azDvJf%2F%2F15ATFtZBhqWiLAvmSD8%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQCj2dCkFGwozYAeXwvkB7hiFAVpNRnYAxVqJE46gUNhhgIgBjbPg%2BrxSff4nSsYy2y1zhkrL2cGM4wj1X52SZWaR6EqiAQI7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDItY8Vy%2FvfCUluaT4SrcA7dgBH5%2BK4wMMoEJGJ0Ng1NAK8ymTD0cKPoj7WUYpivuO10Ao1a6j5nTx1qikLnpexCjGe5%2BZaBLMJTBBdej5SJAUfkUL%2Bol6rfDuQDtlfXuR%2FI%2FzBuJxhmJyWVgRxm%2FXN9XbBKBLLitt5%2BFLyiXQcA8KS%2BmnvRpwDTnbnMSfUmyFkp2qu8KqYYETY1hQA5iQ3OceSWpcBIj4CXqxnuupYlqme9zDgaldQu3lr6jBH1ETyjSEa6SthY4oLzYKwGPfJfaGmrtK8pBTVO9BSd7fUflohKQw8lHqUSNaV4v2xQG40fL9mLQt2IXolFYW1fCCDM5nRg1nvFz%2BZlktWZLICsNZVKGPpeNHngZQolo62upi6hY7nJgkpyJPidHfhbl3Gf%2BaMeGFnrphFsStDfxpa4t%2FmdFkv0s1kSxJHOY%2FQKw4o913J0pF1GDy%2FD4amO9d7p0fOEtUUdjLU%2Fv%2FpWOhJedre8kX5qIIJshb%2BL8tryDMAwLUCLCb2l3gzTlx9jFXNMDyeGT2D%2By8xQrE8wPf7Bycsa0GoOvg5WeY86HM1VBPESvHrWU5brtPcrHrpCm8N3defxUr%2BW7wAskweoM%2FpR1DGC%2FuGMjfT3U5TrOSvhiRmUFRxRm1xuD5HDCMI6BnL4GOqUB2ebcvkEsW7R30QXiCE0n7VwkLsyABYsufWqxk7b2t90yovhnPEvSuMk%2Bgaf5mgiQ1bXGjwE4kSXIcTOqHIz%2Bo9mx6kws63e4YYMssun8FbMyrs0rQC8PeUrbKW2yNoe5aFGC%2BI49YsbR4fzCLCsM4XLY%2Ba9B2GUQRCGwobUA8%2BE505tg3wsRq%2FwLcgzsal3dWSyYAi8jtpr1s0z%2FRcxmqEHwCQA6&Expires=1741702137\n",
      "citations download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/citations/20220513_071330_00037_xkiix_00bc87b3-00b5-4912-91e0-2e7ea0a433a0.gz?AWSAccessKeyId=ASIA5BJLZJPWYHK3B6SQ&Signature=KhZOYWsMHNGDWjivmN6ivq5IFng%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIHp2puQfPFmtQL3dA4nDLBvHn4ov8F3jE77E3LLMz9KOAiEArXksxwN93912mRJEiY%2Fnx82oPvPCM%2F%2FfwMX2YVrwmgsqiAQI7v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDFensHwJO0JM8aISpCrcA1E%2BYfIyrKiTdPmLZcmYWobp0Iwv5mj8Ai1gFdH4O9yHk8X1AZyigTj4QL3eQkOJZVuXLIUMuYadCp6TC%2F5tTfmQcePgX2lpgLyPqSfo1kX5Bk%2BgPNxOWoYof7vt5eLxGhFfmtnTSGg2vmw56utKeZyPp%2Fmt2RDDUPWu4DchXt%2BLzrM%2BYMtrxhullShmjfJlshRvzEFFiJsn%2BTb%2F%2BE%2FdRpJV9U%2BzDJQRmiWRDCxKV088uZQ%2FFmn5%2F1RDwQm7zruG1ggkVfArsgz95ALTLUYy80L9tZIKAWdJhqxt8n35wZj45%2FqnvKuMMTL%2FNAZxHJHpeIfps7MCGtC%2FQSdBHSP8gVaPgPYtyvjE6n%2BqM2g2%2Bna%2FQOsAWvnWOBQoC5%2BLTDd2o4kx%2F3XluhK6ATFyG0oXCtcKBJ0qZ8haMGAhA9LGq1TSFKO%2BUvQv0s0VFL3582UGIRjrI6lnbn1XA0BPmLVmSVk4BHa4QRfG6SYSpUTL2RZ9LoBnxK%2FDmBmJk3HgDibMmMEwWFXXmYiJ3yuxRDROQEhGpFS3uobnR4Hf13ibhrAnENWPyqST1rZ1XCIqYCaNN66yE7matG0JH8QxmO5czzeCOEhPJKtSEFZ7kEzb1KlZQ956ENI0A9jgvUa5MLTym74GOqUBQIBkVSkYGWq0dyUBhJUftxpjv2CvD331WjjITDJPOYZHV8yjwRX9T0mkQqLpU96arPkvS3lOS0D8kn4I3dpublIEuKFmPloFCizosaOQ%2FMZptPO%2BJjLtY8UBA06hQJ%2Bocqu9qvJHFCFzVV39Uz3WgGumwzUpgiXvKqgzR6bR8ehAEMWB56FlZFOxj5UEesik90kKhuY8TuCDYM%2BMcAH9FZi5sIKf&Expires=1741702139\n",
      "embeddings download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/embeddings/20220513_073500_00025_jcu4c_08b8baf2-dfe2-4d95-804a-01e951f4b532.gz?AWSAccessKeyId=ASIA5BJLZJPWWOWIVXNE&Signature=zl3AjX2aSMi8cg49er6jg2s95fo%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQCe0MFp8wVHac1IcVlIVTIxbQQA03%2FstTAT%2FUYv66a2wwIgdKoWpgGvT8qpsh8m%2FcWGBNaZtzE0m0aPZ9TKGpJHOOgqiAQI6%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDHRh3Onp5Q7qs6j8USrcA8Mm65dZAKt%2Ff1F9zaBHOo331Rn8r1xBy5KrqGv3401prvePcrBeMhtEj%2B5DSDVUi948tdo13HJWUpWl8iqwdlobEDc9HL1pnu%2BOb4EuUu80aHOktV21nI%2FcKZ6e0LgR5bTFCJoRmF6iWYNy5Wcl%2FGWxW3ZrSQXIEJDL6ufOBnwccjYtHKitS0dragj2BvDdn%2BzQmTCbda%2Fyht%2FPaxukiYk4XDMTxfauXeqPyVxhqvqE7J4hrBH%2BU4YdyvMgU%2Bz4Fshd58TvZ%2BtqvrHyl6BBj0IRbje1%2F%2FVHtj%2FCblsPRo07lB4o9wi36YCGFOl0E8nG1mavfGQY994GM8z%2B2VlfMDeBbWCNPlbrb5okuW2zlvBR7yx7rY6LC7eYSj0ZDhORh1qDBYeKD%2BxOYPVMbd%2F5RfeREQTTCoBU3JQ6nGxTINRY3A4Ds7JNpP0AUEOGZ%2FYWlGNE8gpIkMdoKRaRK9o19vesHQN61hpqBiODvyZLB1EtPrTPpYmcRDNUphn0vXHD2XEJRziaBkKNTQsMPeWbheew8CrZjICpDF9kqcgaEqlne3th47WgBwmJ3nhuI1sg%2B07wJ9k63WO0OhsY691N%2FZSU7bkDpEpJ7JchY5Np%2Fk9DwUkndev6sX%2FTJRr%2FMJSZm74GOqUBIbUqwTD0Yyhzq97eJVnh5GAujgbd4mLraOxmb%2FikNAqsYp3XJ2wxxzGKwWiNSZQccoJu2oGii6oZVDFrxrBMtfcn2rS6MilrzW4s1%2BIhtoK2nBtUSLTbfvEU8jJbnTA%2BWaK0T30o3bUl82Zp1TpvZtvEpGrh0eyZSYJ2DNbEYGMO33u7xKdenRkN6R2SG8EuUfEv1MMPrpwwvUCaU6soTltsSC3F&Expires=1741702141\n",
      "papers download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/papers/20220513_070151_00012_4bpee_054cd248-48ad-47d6-b0d9-e4fe4333cc61.gz?AWSAccessKeyId=ASIA5BJLZJPW2C4UJQLS&Signature=D%2B8VXUOMXKTftBVdPDz8vStZaEc%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIEsZRh0LCdXLjdJe8GX1cZmIXaOZ3EOeOv%2FcqbuJFTCHAiEAxOl4%2F5OVqEM1YKwlkYiaf9jTVM8DnVfC3m%2BP0GJBYQ0qiAQI7v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDKnnZmJQ7pq7ZPFOVCrcA6tW%2B5g9S1Bj6dDzqKHHtLbR0FKpzsAp9jhkouJgeLR6e%2BOk0Au0WFAdGZWGK1c0jLcX3V2VJryE%2Fyv1JKbKTjqjnd%2FsKVCf3kKojm6W0aI3f6yM6wSvfjVGVBIfW5LFa7cHtytpWBj4XB%2FZaup6DL%2F%2Bu%2BgsLAPdAdeuEtqXAdXVwAbybSf%2BtIpxs0q5iAX5F6H6aseb6eLx40v%2BLmPkpkEDhrH6KA9mcC9D8De0xxv7wrLao8fzKsYTd6gWYUukSRfw122dHLucygvDDcaaCxOTeNc757owfxhhW65g5Yj5iQjnnpvGMpNZWBWRk7%2FtvH1iPI7%2BtnkdGMY6Bk4RdyDMelLYB9W2okVZ1mu%2Ffsa5Ry%2B9bQRox%2F%2BSBxQdcbdK6vvX6go7DQOtQl9VXdGPjlEWROJhWPDB8pGrGBi9zxU8QN3BUsOlAs8ljeavTyEv0fbitxyk7kP7JXHTfC0rHQZDVlBdOtuQYdMcB59c57GWr8tWfJji5tMEewrA1dZHCakkXlEwLFwEbe7S87ZdASGi%2BFGuFfHfsILz4J7Kgtk9zI%2BehKzg91VOtIHP8ixs%2FLwQvHjHNBAKxkCtr8ZxYCTPc1l3Afb7moYGaVTkO7OcZXddrqq3ItztIGrJMMjjm74GOqUBVyM3YPnLClMRW21OdkGFhDy3%2BNnCE5sRIQ14pojfLz98N83dskJxfG9XTTrXnr5d%2B7xO2qkJuA8zdBy%2BSqTU5wKTGvAiyOqLOGsRJXRN5MIgiTnurPF1OGXwK0Lkiscn0n96l%2BtB5bdefsVCv4k%2BlK2PTXV%2BzJi4N4C2gCZybyPtfDbAsAJXhbV9%2FgojKJBZecDAkeJ6P6vR7CM5Q4wXrDGCocR9&Expires=1741702143\n",
      "s2orc download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/s2orc/20220519_000932_00025_dauyy_04c9ef07-dd83-42f4-b36a-4d3ea06c99b0.gz?AWSAccessKeyId=ASIA5BJLZJPW6RPRBKYK&Signature=mYMngJUkzFu44M74O%2BYV5y5E1%2Bw%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCICWX9sJwOgHxQ9UcvIYbesYW%2FrYm3hAWbhySw%2BCDxhKYAiEA8%2BX4MM0EcUH%2F%2BtrjpyRxj3oNXIwgHFKk3YDAftA98pwqiAQI6v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDNVRgNpJ%2B2B1D0TggSrcA%2BevQRoigDGj3em7vtBG%2FcKmVFwCEgYR8DH6jBWXkUUjF6Xi8%2Fwu%2BhyVzmA3eKG1WtCg0Ol5IXSRL4IuYbB42h6nxmEwcO9TuW1ysitbms3LrD%2BaQ8D%2Bz5wzzHkDJKACwh%2FWyTm1ck9hFYKtlWtWdwStktMOzvdJZeGHl%2F%2FR353dSQFC%2Bk62MQ5VGFmM16qgNpbQdjdLWtx%2Fyjmu67UR97nq18U0CiSndkHgQ4BcJ4cJALdScH%2FMu30TbJsVZDRw%2FdUkUDq%2F0CMUN47sNBALkhbp7%2BGxB%2FprcqUUU6OKtHauEO7HAp5zEvpqV98BwP9e%2FVUHjs%2FLspzQ0usT5hXCygRZYr2%2BEl8MlstxO9TsyzclD%2FFWVpXT5v6DeIbL%2BEhEwRHpopaVciBSm2h4pnDr3kYsF8RQjDt%2Bp%2FAMuDCyuOrwIT7azWe%2BxMwG0nuWtrTL5KLRst3hN7FYieG7GPm5izD5d073zGavExX2WEue9NQaqq%2BmAjcJs2K41FMP4ci1oDm%2BHl79VYwAkG9YTyUy6k3vIeetHIFQhK9g8YuCEhLheaS5fx9AdOtRYQgOUpT2J7TYJ0965eWQbUsewSVaM2fmJrZpuRkGhyeGjwe0BtccTTCK6oOGQxeN4hR%2FMIWDm74GOqUBfY9lXmEokNwZWwIltbvOAv61wlaBS3ZlgMOi9r2aV5gyz%2F%2BuWCm6B8KXa5%2BjXAcxU6NnWhhwc4QhqlBKZwspSmSswhnz2TxKF7p0n%2FOF866XRzUf0mM4QvfFHFKEJcfsqud8NGrjEv%2B4TRRkU8NMYGlCHNHAfD5dhPVxvqb5Clu88o5Bql%2BEXzkP2SMKLu6X%2BsRRKawEONE7Cq2p%2BA3eayF5U4dx&Expires=1741702145\n",
      "tldrs download url:\n",
      "https://ai2-s2ag.s3.amazonaws.com/staging/2022-05-10/tldrs/20220513_073419_00109_m3j5m_02586bff-4a75-46c4-8f1f-e2d8ad0bbf75.gz?AWSAccessKeyId=ASIA5BJLZJPW66CEBZ3V&Signature=xFenalnCuq9lUWcVlqirOO0Kt4E%3D&x-amz-security-token=IQoJb3JpZ2luX2VjELP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIBUb90pJEMuYH40rvMi4E%2FmZTYsSmL64%2FjzeSsUXCxBfAiEApI1qo54ORyQiLoZ1U56OYGiM%2BM47M5dYVc6JkgvTvLAqiAQI7P%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw4OTYxMjkzODc1MDEiDOBOLdT%2BQGW4ZmFoYSrcA3SM%2BJHeK6iP%2FkFo%2BJ5iXI%2BFDTOJMVsngCC9iMAEaIAyjsy%2FSCbdE0ZxXx9biXlhorsOfnOtAaRogLORo2POLAqr1eD0q9JVeHJ6fkKgFVT791mzBO3iteEFZ8uWWE02ux0AVT6q8Qc5RD2%2F5dM3%2BlUhoV8zVAC8oO1aarHIKTf%2FaZ7AYV8F%2FsfaIl9INbWaesc2uC3KXS6XSnYUA%2B9pyJPmcpGJVtlFXbT%2BVj9bkcTCjkiBzcHEHxYQrAYIQGDyRSuM5jRdfZZptswxEgXOeq0DuXrb871tuWV9HLG8d3XdpkdoXFbWsMpQn1kFsE4As1QAPadiMIDDzvw1zlYgagwLRIjz8oz99e2zfsUkHOi3D80XgxHTySbkv%2F1CNeuwZ3ih6MhO3qlXOI73meS5LlS2QRc6TQhQVEJFaCHeIs9sCB96gqwkLqhzeU7O5q3jctOTTkz6I%2F0vCqQZlpB%2FVww5Xk1NXEplAt9pkFOzGvv81nJjrTH05CEMHy17vNJ%2Bz%2FVxitUETYFWLd3Klk5ifmYOd6vpbI7b9%2BsnQoFuRsnhh89JmfKLlj9uFRpRpq89%2BSFkyaUT9xjM%2FTYFep2QaDoBVYu%2B4HyYLHnQ0GIqA7wTiPuE8o6VJjRCOnKAMLm0m74GOqUBdOUcLGlEjRq5DY4MZl420gogWfstS6DUBul%2FeUTHmUFlKGs5nXPf%2B%2FoIfWJl%2B6Sy8rZGnWxvtbRFLVOShJh%2BJN%2BR5dYgFDJqZpKq1uLCldxhbQmndAPJYtHB02yD0HjM%2B3KaBifIu3vBfOQcKY7PaFTz43%2FmGKmJPd%2FqGnCuMc33cWkeKFIfUrcRJbi8h9NvAqRzvlm5%2FoJ%2Bb%2F8CthtaZ%2BjnjmFP&Expires=1741702147\n"
>>>>>>> 7306732bf11aa73b3a1303524405ca1494b496cc
     ]
    }
   ],
   "source": [
    "# This endpoint requires authentication via api key\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "for name in dbs:\n",
    "    sleep(1)\n",
    "    # Define dataset name you want to download\n",
    "    dataset_name = name\n",
    "    # Send the GET request and store the response in a variable\n",
    "    response = requests.get(base_url + release_id + '/dataset/' + dataset_name, headers=headers)\n",
    "    print(name+\" download url:\")\n",
    "    url=json.loads(response.text)[\"files\"][0]\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put each json file in a folder called rawdata and change their names to the appropiate ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start cleaning the data, we will start with the papers and keywords. First let's define the conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition for deleting a row\n",
    "def conference_conditions(json_obj):\n",
    "    if json_obj[\"authors\"] == []:\n",
    "        return True\n",
    "    elif json_obj[\"venue\"] == None:\n",
    "        return True\n",
    "    elif json_obj[\"s2FieldsOfStudy\"] == None:\n",
    "        return True\n",
    "\n",
    "def journal_conditions(json_obj):\n",
    "    if json_obj[\"authors\"] == []:\n",
    "        return True \n",
    "    elif json_obj[\"journal\"] == None or \"name\" not in json_obj[\"journal\"] or \"pages\" not in json_obj[\"journal\"] or \"volumen\" not in json_obj[\"journal\"]:\n",
    "        return True\n",
    "    elif json_obj[\"s2FieldsOfStudy\"] == None:\n",
    "        return True\n",
<<<<<<< HEAD
    "    \n",
    "def save_to_csv(json_obj, filename):\n",
    "\n",
    "                  \n",
=======
    "    elif \"Review\" not in json_obj[\"publicationtypes\"] and \"Conference\" not in json_obj[\"publicationtypes\"] and \"JournalArticle\" not in json_obj[\"publicationtypes\"]:\n",
    "        return True\n",
    "    elif json_obj[\"s2fieldsofstudy\"] == None:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified JSONL saved to csv/papers.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"rawdata/papers\"   # Path to your JSONL file\n",
    "output_file = \"csv/papers.csv\"  # Output file where changes will be saved\n",
    "keywords_file=\"csv/keywords.csv\"\n",
    "RECORDS = 15000  # Number of records to save    \n",
    "count=0     \n",
    "# Read, modify, and save the updated JSONL content\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile,open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile, open(keywords_file, \"w\", newline='', encoding=\"utf-8\") as keyfile:\n",
    "         \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"corpusid\", \"title\", \"authorId\", \"authorName\", \"url\", \"year\", \"referencecount\", \"citationcount\", \"influentialcitationcount\",\"publicationtype\", \"publicationdate\", \"venue\", \"publicationvenueid\", \"journalName\", \"journalVolume\", \"journalPages\"])\n",
    "    csv_writer_2 = csv.DictWriter(keyfile, fieldnames=[\"sid\", \"keyword\"])  \n",
    "    \n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    csv_writer_2.writeheader()\n",
    "    \n",
    "    for line in infile:\n",
    "        if count >= RECORDS:\n",
    "            break\n",
    "        try:\n",
    "            # Parse the JSON object\n",
    "            json_line = json.loads(line)        \n",
    "            # Check if the row matches the deletion condition\n",
    "            if not delete_conditions(json_line):\n",
    "                count+=1\n",
    "                json_line[\"authorId\"] = json_line[\"authors\"][0][\"authorId\"]\n",
    "                json_line[\"authorName\"] = json_line[\"authors\"][0][\"name\"]\n",
    "                if \"Conference\" in json_line[\"publicationtypes\"]:\n",
    "                    json_line[\"publicationtypes\"]=\"Conference\"\n",
    "                    json_line[\"journalName\"]=None\n",
    "                    json_line[\"journalVolume\"]=None\n",
    "                    json_line[\"journalPages\"]=None\n",
    "                elif \"Review\" in json_line[\"publicationtypes\"]:\n",
    "                    json_line[\"publicationtypes\"]=\"Workshop\"\n",
    "                    json_line[\"journalName\"]=None\n",
    "                    json_line[\"journalVolume\"]=None\n",
    "                    json_line[\"journalPages\"]=None \n",
    "                elif \"JournalArticle\" in json_line[\"publicationtypes\"]:\n",
    "                    json_line[\"publicationtypes\"]=\"JournalArticle\"\n",
    "                    json_line[\"venue\"]=None\n",
    "                    json_line[\"publicationvenueid\"]=None\n",
    "                    json_line[\"journalName\"]=json_line[\"journal\"][\"name\"]\n",
    "                    json_line[\"journalVolume\"]=json_line[\"journal\"][\"volume\"]\n",
    "                    if json_line[\"journal\"][\"pages\"] is not None:\n",
    "                        json_line[\"journalPages\"]=re.sub(r'\\s+', '', json_line[\"journal\"][\"pages\"])\n",
    "                    else:\n",
    "                        json_line[\"journalPages\"]=None\n",
>>>>>>> 7306732bf11aa73b3a1303524405ca1494b496cc
    "                \n",
    "                row_papers = {\n",
    "                \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                \"corpusid\": json_line.get(\"corpusid\"),\n",
    "                \"title\":  json_line.get(\"title\").strip().replace(\"\\n\", \" \"),\n",
    "                \"authorId\": json_line.get(\"authorId\"),\n",
    "                \"authorName\": json_line.get(\"authorName\"),\n",
    "                \"url\": json_line.get(\"url\"),\n",
    "                \"year\": json_line.get(\"year\"),\n",
    "                \"referencecount\": json_line.get(\"referencecount\"),\n",
    "                \"citationcount\": json_line.get(\"citationcount\"),\n",
    "                \"influentialcitationcount\": json_line.get(\"influentialcitationcount\"),\n",
    "                \"publicationtype\": json_line.get(\"publicationtypes\"),\n",
    "                \"publicationdate\": json_line.get(\"publicationdate\"),\n",
    "                \"venue\": json_line.get(\"venue\", ''),\n",
    "                \"publicationvenueid\": json_line.get(\"publicationvenueid\", ''),\n",
    "                \"journalName\": json_line.get(\"journalName\"),\n",
    "                \"journalVolume\": json_line.get(\"journalVolume\"),\n",
    "                \"journalPages\": json_line.get(\"journalPages\")\n",
    "                }\n",
    "                # Write the row to CSV 1\n",
    "                csv_writer_1.writerow(row_papers)\n",
    "\n",
    "                keywords=list()\n",
    "                for keyword in json_line.get(\"s2fieldsofstudy\", []):\n",
    "                    keywords.append(keyword[\"category\"])\n",
    "                keywords = list(set(keywords))\n",
    "                for keyword in keywords:\n",
    "                    row_keywords = {\n",
    "                        \"sid\": count, # We will use the surrogated ID here, just in case\n",
    "                        \"keyword\": keyword\n",
    "                    }\n",
    "                    # Write the row to CSV 2 for each keyword\n",
    "                    csv_writer_2.writerow(row_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Modified JSONL saved to csv/papers.csv\n"
=======
      "[\n",
      "  {\n",
      "    \"paperId\": \"649def34f8be52c8b66281af98ae884c09aef38b\",\n",
      "    \"abstract\": \"We describe a deployed scalable system for organizing published scientific literature into a heterogeneous graph to facilitate algorithmic manipulation and discovery. The resulting literature graph consists of more than 280M nodes, representing papers, authors, entities and various interactions between them (e.g., authorships, citations, entity mentions). We reduce literature graph construction into familiar NLP tasks (e.g., entity extraction and linking), point out research challenges due to differences from standard formulations of these tasks, and report empirical results for each task. The methods described in this paper are used to enable semantic features in www.semanticscholar.org.\",\n",
      "    \"references\": [\n",
      "      {\n",
      "        \"paperId\": \"1fec9d41d372267b4474f18cbeadd806c8b67adb\",\n",
      "        \"title\": \"Extracting Scientific Figures with Distantly Supervised Neural Networks\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"921b2958cac4138d188fd5047aa12bbcf37ac867\",\n",
      "        \"title\": \"Content-Based Citation Recommendation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"2264e14e35dc5a3db93437bc408a03171af8c59d\",\n",
      "        \"title\": \"The AI2 system at SemEval-2017 Task 10 (ScienceIE): semi-supervised end-to-end entity and relation extraction\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"6bed23ebd9998e85bad446b9a56ea53f463d0f8a\",\n",
      "        \"title\": \"Learning to Predict Citation-Based Impact Measures\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"32ce5467ff884d2f90a233f4d9606c6e18b1a9d6\",\n",
      "        \"title\": \"Learning a Neural Semantic Parser from User Feedback\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"a26accf878216be4388ad9a0474e658aa03d33e2\",\n",
      "        \"title\": \"SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"b30481dd5467a187b7e1a5a2dd326d97cafd95ac\",\n",
      "        \"title\": \"Explicit Semantic Ranking for Academic Search via Knowledge Graph Embedding\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38\",\n",
      "        \"title\": \"Semi-supervised sequence tagging with bidirectional language models\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"74a69228157b3fa1c7adc14e7715039e54f4b067\",\n",
      "        \"title\": \"MetaMap Lite: an evaluation of a new Java implementation of MetaMap\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"61322ec6cfc54fe9723d4637239b8fb9938dc501\",\n",
      "        \"title\": \"BioCreative V CDR task corpus: a resource for chemical disease relation extraction\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f5a7da72496e2ca8edcd9f9123773012c010cfc6\",\n",
      "        \"title\": \"Neural Architectures for Named Entity Recognition\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"8ffcad9346c4978a211566fde6807d6fb4bfa5ed\",\n",
      "        \"title\": \"TabEL: Entity Linking in Web Tables\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"c6b53dd64d79a59f49f261baac8d2581a29ca06a\",\n",
      "        \"title\": \"Design Challenges for Entity Linking\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1c7be3fc28296a97607d426f9168ad4836407e4b\",\n",
      "        \"title\": \"Identifying Meaningful Citations\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"d755a7e943009af26e0a5b617ef60c29c1d4f4e0\",\n",
      "        \"title\": \"CHEMDNER: The drugs and chemical names extraction challenge\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\n",
      "        \"title\": \"GloVe: Global Vectors for Word Representation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"dfb25cf7efec9a7c114f6327e4b06a306cce5cb6\",\n",
      "        \"title\": \"CiteSeerX: AI in a Digital Library Search Engine\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"43bfbc53482a83e2141d044493ccbb65a472be55\",\n",
      "        \"title\": \"Clinical review: Efficacy of antimicrobial-impregnated catheters in external ventricular drainage - a systematic review and meta-analysis\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"e23020fdab3e46254468f694c159d7d6a3a9fb55\",\n",
      "        \"title\": \"Search needs a shake-up\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"ecfaab27ac62f6a63146b6d75ae9f9d232abd31b\",\n",
      "        \"title\": \"Exploiting MeSH indexing in MEDLINE to generate a data set for word sense disambiguation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"bc1022b031dc6c7019696492e8116598097a8c12\",\n",
      "        \"title\": \"Natural Language Processing (Almost) from Scratch\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"b18fbdff9b5feac766bd9cde9b266de274d8c4b2\",\n",
      "        \"title\": \"TAGME: on-the-fly annotation of short text fragments (by wikipedia entities)\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"9f62067945d991cd78a62cf647de17f01d1b54d3\",\n",
      "        \"title\": \"Frustratingly Easy Domain Adaptation\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"2e9d221c206e9503ceb452302d68d10e293f2a10\",\n",
      "        \"title\": \"Long Short-Term Memory\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"1f6c303718a69f0a74b8dd85ba5dfaf4df08e18d\",\n",
      "        \"title\": \"Swanson linking revisited: Accelerating literature-based discovery across domains using a conceptual influence graph\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"20432d7fec7b15f414f51a1e4fe1983f353eff9d\",\n",
      "        \"title\": \"Author Disambiguation using Error-driven Machine Learning with a Ranking Loss Function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"paperId\": \"f712fab0d58ae6492e3cdfc1933dae103ec12d5d\",\n",
      "    \"abstract\": \"This paper introduces a new multi-strain epidemic model with reinfection and cross-immunity to provide insights into the resurgence of the COVID-19 epidemic in an area with reportedly high seroprevalence due to a largely unmitigated outbreak: the state of Amazonas, Brazil. Although high seroprevalence could have been expected to trigger herd immunity and prevent further waves in the state, we have observed persistent levels of infection after the first wave and eventually the emergence of a second viral strain just before an augmented second wave. Our experiments suggest that the persistent levels of infection after the first wave may be due to reinfection, whereas the higher peak at the second wave can be explained by the emergence of the second variant and a low level of cross-immunity between the original and the second variant. Finally, the proposed model provides insights into the effect of reinfection and cross-immunity on the long-term spread of an unmitigated epidemic.\",\n",
      "    \"references\": [\n",
      "      {\n",
      "        \"paperId\": \"245330d00fea9ebbefa164986d056c8d8f3b873e\",\n",
      "        \"title\": \"Covid-19: Peru\\u2019s official death toll triples to become world\\u2019s highest\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"0064e495e9f04d0a0c7b94d6bf9c198d3925fed7\",\n",
      "        \"title\": \"Genomics and epidemiology of the P.1 SARS-CoV-2 lineage in Manaus, Brazil\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"300fc77d79d9b0c75ee5b036ac69c0330fb2259a\",\n",
      "        \"title\": \"Covid-19: Is Manaus the final nail in the coffin for natural herd immunity?\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"22f4801ad3d5c46f7ad6c24acee049989c443085\",\n",
      "        \"title\": \"Resurgence of COVID-19 in Manaus, Brazil, despite high seroprevalence\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"fd6ebb8b7498c0401ac0e7b0107b75705bf55b0b\",\n",
      "        \"title\": \"Comprehensive mapping of mutations to the SARS-CoV-2 receptor-binding domain that affect recognition by polyclonal human serum antibodies\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"687ef0398b474c38df97bcd0d985ac1c794fb874\",\n",
      "        \"title\": \"Three-quarters attack rate of SARS-CoV-2 in the Brazilian Amazon during a largely unmitigated epidemic\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"6cd5bd85dadc907ae8aa5a7a4fffecc3e6e9e404\",\n",
      "        \"title\": \"Using Benford\\u2019s law to assess the quality of COVID-19 register data in Brazil\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"33bc8aa51d350352b8508b346421fa012d574c07\",\n",
      "        \"title\": \"Genomic evidence for reinfection with SARS-CoV-2: a case study\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"dab85d00ab9d6df536d31df970510ceaed99b7c3\",\n",
      "        \"title\": \"Viral epitope profiling of COVID-19 patients reveals cross-reactivity and correlates of severity\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"297d33202790b3b839e440256bf8ff6a76c0792b\",\n",
      "        \"title\": \"COVID-19 herd immunity: where are we?\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"33476769fec9c469b65befcb4c0497c07ecf964f\",\n",
      "        \"title\": \"Flattening the curves: on-off lock-down strategies for COVID-19 with an application to Brazil\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"e0223f1944bafe098f9f1b28ada83fab85b686df\",\n",
      "        \"title\": \"Estimates of the severity of coronavirus disease 2019: a model-based analysis\"\n",
      "      },\n",
      "      {\n",
      "        \"paperId\": \"95c90a2fe671f40a6d7c4c9a3d664741513e1bbc\",\n",
      "        \"title\": \"Incubation period of 2019 novel coronavirus (2019-nCoV) infections among travellers from Wuhan, China, 20\\u201328 January 2020\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
>>>>>>> 7306732bf11aa73b3a1303524405ca1494b496cc
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "output_file = \"csv/papers.csv\"  \n",
    "keywords_file=\"csv/keywords.csv\"\n",
    "\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "#********************************************************************************************************************\n",
    "RECORDS = 50  # Number of records to save per cathegory \n",
    "PUBLICATION_TYPES = [\"Conference\", \"JournalArticle\"]  # Publication types to filter (There is not Workshop)\n",
    "QUERY = \"data\"  # Query to filter the papers\n",
    "FIELDS = \"paperId,corpusId,title,abstract,authors,url,year,referenceCount,citationCount,influentialCitationCount,s2FieldsOfStudy,publicationDate,journal,venue,publicationVenue\"  # Fields to retrieve from the API\n",
    "#********************************************************************************************************************\n",
    "\n",
    "query_encoded = urllib.parse.quote(QUERY)\n",
    "fields_encoded = urllib.parse.quote(FIELDS)\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile  :   \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"paperId\",\"corpusId\", \"title\", \"authorId\", \"authorName\", \"url\", \"year\", \"referenceCount\", \"citationCount\", \"influentialCitationCount\",\"publicationType\", \"publicationDate\"])\n",
    "\n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    for publication_type in PUBLICATION_TYPES:\n",
    "        type_encoded = urllib.parse.quote(publication_type)\n",
    "        url1=\"https://api.semanticscholar.org/graph/v1/paper/search?query=\"+query_encoded+\"&publicationTypes=\"+type_encoded+\"&fields=\"+fields_encoded+\"&limit=\"+str(RECORDS)\n",
    "        response = requests.get(url1, headers=headers).json()\n",
    "        for line in response[\"data\"]:\n",
    "            count += 1\n",
    "            try:  \n",
    "                if publication_type==\"Conference\":\n",
    "                    if not conference_conditions(line):\n",
    "                        line[\"publicationType\"]=\"Conference\"\n",
    "                        line[\"journalName\"]=None\n",
    "                        line[\"journalVolume\"]=None\n",
    "                        line[\"journalPages\"]=None\n",
    "                elif publication_type==\"JournalArticle\":\n",
    "                    if not journal_conditions(line):\n",
    "                        line[\"publicationType\"]=\"JournalArticle\"\n",
    "                        line[\"venue\"]=None\n",
    "                        line[\"journalName\"]=line[\"journal\"][\"name\"]\n",
    "                        line[\"journalVolume\"]=line[\"journal\"][\"volume\"]\n",
    "                        if line[\"journal\"][\"pages\"] is not None:\n",
    "                            line[\"journalPages\"]=re.sub(r'\\s+', '', line[\"journal\"][\"pages\"])\n",
    "                        else:\n",
    "                            line[\"journalPages\"]=None    \n",
    "                line[\"authorId\"] = line[\"authors\"][0][\"authorId\"]\n",
    "                line[\"authorName\"] = line[\"authors\"][0][\"name\"]\n",
    "                row_papers = {\n",
    "                    \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                    \"paperId\": line.get(\"paperId\"),\n",
    "                    \"corpusId\": line.get(\"corpusId\"),\n",
    "                    \"title\":  line.get(\"title\").strip().replace(\"\\n\", \" \"),\n",
    "                    \"authorId\": line.get(\"authorId\"),\n",
    "                    \"authorName\": line.get(\"authorName\"),\n",
    "                    \"url\": line.get(\"url\"),\n",
    "                    \"year\": line.get(\"year\"),\n",
    "                    \"referenceCount\": line.get(\"referenceCount\"),\n",
    "                    \"citationCount\": line.get(\"citationCount\"),\n",
    "                    \"influentialCitationCount\": line.get(\"influentialCitationCount\"),\n",
    "                    \"publicationType\": line.get(\"publicationType\"),\n",
    "                    \"publicationDate\": line.get(\"publicationDate\"),\n",
    "                }\n",
    "                csv_writer_1.writerow(row_papers)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "print(f\"Modified JSONL saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.semanticscholar.org/graph/v1/6432563/citations\n",
      "{\n",
      "  \"error\": \"Not found\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor id in ids: \\n    url = \"https://api.semanticscholar.org/graph/v1/\"+str(id)+\"/citations\"\\n    print(url)\\n\\n    response = requests.get(url, headers=headers).json()\\n    print(json.dumps(response, indent=2))\\n# Save the results to json file\\n\\nwith open(output_file, \"w\", newline=\\'\\', encoding=\"utf-8\") as outfile  :   \\n    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"authorId\", \"url\", \"name\", \"paperCount\", \"hIndex\"])\\n\\n    # Write the headers to the CSV files\\n    csv_writer_1.writeheader()\\n    for line in response:\\n        count+=1\\n        try:  \\n            row_papers = {\\n                        \"sid\": count, # Add a new column with a surrogated ID, just in case\\n                        \"authorId\": line.get(\"authorId\"),\\n                        \"url\": line.get(\"url\"),\\n                        \"name\": line.get(\"name\"),\\n                        \"paperCount\": line.get(\"paperCount\"),\\n                        \"hIndex\": line.get(\"hIndex\")\\n                        }\\n            # Write the row to CSV 1\\n            csv_writer_1.writerow(row_papers)\\n        except json.JSONDecodeError as e:\\n            print(f\"Error decoding JSON: {e}\")\\nprint(f\"Modified JSONL saved to {output_file}\")\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file=\"csv/citations.csv\"\n",
    "papers_file = \"csv/papers.csv\"  \n",
    "\n",
    "\n",
    "df=pd.read_csv(papers_file)\n",
    "ids=df[\"corpusid\"].values.tolist()\n",
    "\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "url = \"https://api.semanticscholar.org/graph/v1/6432563/citations\"\n",
    "print(url)\n",
    "\n",
    "response = requests.get(url, headers=headers).json()\n",
    "print(json.dumps(response, indent=2))\n",
    "\n",
    "\"\"\"\n",
    "for id in ids: \n",
    "    url = \"https://api.semanticscholar.org/graph/v1/\"+str(id)+\"/citations\"\n",
    "    print(url)\n",
    "\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "    print(json.dumps(response, indent=2))\n",
    "# Save the results to json file\n",
    "\n",
    "with open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile  :   \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"authorId\", \"url\", \"name\", \"paperCount\", \"hIndex\"])\n",
    "\n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    for line in response:\n",
    "        count+=1\n",
    "        try:  \n",
    "            row_papers = {\n",
    "                        \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                        \"authorId\": line.get(\"authorId\"),\n",
    "                        \"url\": line.get(\"url\"),\n",
    "                        \"name\": line.get(\"name\"),\n",
    "                        \"paperCount\": line.get(\"paperCount\"),\n",
    "                        \"hIndex\": line.get(\"hIndex\")\n",
    "                        }\n",
    "            # Write the row to CSV 1\n",
    "            csv_writer_1.writerow(row_papers)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "print(f\"Modified JSONL saved to {output_file}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-api-key\u001b[39m\u001b[38;5;124m\"\u001b[39m: api_key}\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Send the API request\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mquery_params, json\u001b[38;5;241m=\u001b[39mdata, headers\u001b[38;5;241m=\u001b[39mheaders)\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save the results to json file\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile  :   \n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "url = \"https://api.semanticscholar.org/graph/v1/author/batch\"\n",
    "output_file=\"csv/authors.csv\"\n",
    "papers_file = \"csv/papers.csv\" \n",
    "count=0  \n",
    "query_params = {\n",
    "    \"fields\": \"name,url,paperCount,hIndex\"#,papers\"\n",
    "}\n",
    "\n",
    "df=pd.read_csv(papers_file)\n",
    "ids=df[\"authorId\"].values.tolist()\n",
    "\n",
    "data = {\n",
    "    \"ids\": ids\n",
    "}\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "# Send the API request\n",
    "response = requests.post(url, params=query_params, json=data, headers=headers).json()\n",
    "# Save the results to json file\n",
    "with open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile  :   \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"authorId\", \"url\", \"name\", \"paperCount\", \"hIndex\"])\n",
    "\n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    for line in response:\n",
    "        count+=1\n",
    "        try:  \n",
    "            row_papers = {\n",
    "                        \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                        \"authorId\": line.get(\"authorId\"),\n",
    "                        \"url\": line.get(\"url\"),\n",
    "                        \"name\": line.get(\"name\"),\n",
    "                        \"paperCount\": line.get(\"paperCount\"),\n",
    "                        \"hIndex\": line.get(\"hIndex\")\n",
    "                        }\n",
    "            # Write the row to CSV 1\n",
    "            csv_writer_1.writerow(row_papers)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "print(f\"Modified JSONL saved to {output_file}\")"
=======
    "#response = requests.get(\"https://api.semanticscholar.org/graph/v1/paper/corpusid:238221832\", headers=headers)\n",
    "\n",
    "r = requests.post(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "    params={'fields': 'abstract,references'},\n",
    "    json={\"ids\": [\"649def34f8be52c8b66281af98ae884c09aef38b\", \"ARXIV:2106.15928\"]}\n",
    ")\n",
    "print(json.dumps(r.json(), indent=2))"
>>>>>>> 7306732bf11aa73b3a1303524405ca1494b496cc
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo4j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, json, os, csv, re, urllib.parse\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from contextlib import ExitStack\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_paper(paper):\n",
    "    return paper['paperId'] is not None and paper['authors'] and paper['abstract'] is not None and paper['title'] is not None and paper['year'] is not None\n",
    "\n",
    "\n",
    "def is_valid_conference(paper):\n",
    "    return paper[\"venue\"] is not None\n",
    "\n",
    "\n",
    "def is_valid_journal(paper):\n",
    "    return paper[\"journal\"] is not None and \"name\" in paper[\"journal\"] and \"pages\" in paper[\"journal\"] and \"volume\" in paper[\"journal\"]\n",
    "\n",
    "\n",
    "def get_referencing_author_id(authors):\n",
    "    return authors[0]['authorId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Needed\n",
    "- paper (w abstract and relevant author) \n",
    "- paper-paper (n-n)\n",
    "- author \n",
    "- paper-author (n-n)\n",
    "- paper-reviewers (n-n)\n",
    "- keywords\n",
    "- paper-keywords (n-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = {\n",
    "    \"paper\": [\"paperId\",\"corpusId\", \"title\", \"referenceAuthorId\", \"abstract\", \"url\", \"year\", \"publicationType\", \"publicationDate\"],\n",
    "    \"paper_paper\": [\"citingPaperId\", \"citedPaperId\"],\n",
    "    \"author\": [\"authorId\", \"authorName\"],\n",
    "    \"paper_author\": [\"paperId\", \"authorId\"],\n",
    "    \"paper_reviewer\": [\"paperId\", \"reviewAuthorId\"],\n",
    "    \"keywords\": [\"keyword\"],\n",
    "    \"paper_keywords\": [\"paperId\", \"keyword\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************************************************************\n",
    "RECORDS = 100  # Number of records to save per category \n",
    "QUERY = \"data\"  # Query to filter the papers\n",
    "FIELDS = \"paperId,corpusId,title,abstract,authors,url,year,s2FieldsOfStudy,publicationDate,journal,venue,publicationVenue,references.paperId\"  # Fields to retrieve from the API\n",
    "#********************************************************************************************************************\n",
    "\n",
    "query_encoded = urllib.parse.quote(QUERY)\n",
    "fields_encoded = urllib.parse.quote(FIELDS)\n",
    "type_encoded = urllib.parse.quote(\"Conference,JournalArticle\")\n",
    "\n",
    "starting_papers_url=\"https://api.semanticscholar.org/graph/v1/paper/search?query=\"+query_encoded+\"&publicationTypes=\"+type_encoded+\"&fields=paperId&limit=\"+str(RECORDS)\n",
    "response = requests.get(starting_papers_url, headers=headers).json()\n",
    "starting_papers = response[\"data\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_papers(processed_papers, to_be_processed_papers, processing_papers, new_papers):\n",
    "    new_papers.discard(None)\n",
    "    for paper in new_papers:\n",
    "        if paper not in processed_papers and paper not in to_be_processed_papers and paper not in processing_papers:\n",
    "            to_be_processed_papers.add(paper)\n",
    "\n",
    "\n",
    "def choose_n_papers_to_process(to_be_processed_papers, n):\n",
    "    return {to_be_processed_papers.pop() for _ in range(min(n, len(to_be_processed_papers)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200\n",
    "MAX_RECURSION = 10\n",
    "csv_folder = Path('csv')\n",
    "\n",
    "processed_papers = set()\n",
    "to_be_processed_papers = set()\n",
    "starting_papers_ids = set([paper['paperId'] for paper in starting_papers])\n",
    "process_new_papers(processed_papers, to_be_processed_papers, set(), starting_papers_ids)\n",
    "\n",
    "set_authors = set()\n",
    "set_keywords = set()\n",
    "set_papers = set()\n",
    "\n",
    "with ExitStack() as stack:  # Ensures all files are closed properly\n",
    "    files = {name: stack.enter_context(open(csv_folder / (name + '.csv'), \"w\", newline='', encoding=\"utf-8\")) for name in csv_files}\n",
    "    writers = {name: csv.DictWriter(files[name], fieldnames=fieldnames, delimiter=\"|\") for name, fieldnames in csv_files.items()}\n",
    "    recursion_block = 0\n",
    "\n",
    "    for writer in writers.values():\n",
    "        writer.writeheader()\n",
    "\n",
    "    while to_be_processed_papers:\n",
    "        recursion_block+=1\n",
    "        if recursion_block > MAX_RECURSION:\n",
    "            break\n",
    "\n",
    "        processing_papers_id = choose_n_papers_to_process(to_be_processed_papers, BATCH_SIZE)\n",
    "\n",
    "        processing_papers_data = requests.post(\n",
    "            'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "            params={'fields': FIELDS},\n",
    "            json={\"ids\": list(processing_papers_id)},\n",
    "            headers=headers\n",
    "        ).json()\n",
    "        \n",
    "        for paper in processing_papers_data:\n",
    "            try:  \n",
    "                processed_papers.add(paper['paperId'])\n",
    "                if not is_valid_paper(paper):\n",
    "                    continue\n",
    "                if is_valid_conference(paper):\n",
    "                    paper[\"publicationType\"]=\"Conference\"\n",
    "                    paper[\"journalName\"]=None\n",
    "                    paper[\"journalVolume\"]=None\n",
    "                    paper[\"journalPages\"]=None\n",
    "                elif is_valid_journal(paper):\n",
    "                    paper[\"publicationType\"]=\"JournalArticle\"\n",
    "                    paper[\"venue\"]=None\n",
    "                    paper[\"journalName\"]=paper[\"journal\"][\"name\"]\n",
    "                    paper[\"journalVolume\"]=paper[\"journal\"][\"volume\"]\n",
    "                    if paper[\"journal\"][\"pages\"] is not None:\n",
    "                        paper[\"journalPages\"]=re.sub(r'\\s+', '', paper[\"journal\"][\"pages\"])\n",
    "                    else:\n",
    "                        paper[\"journalPages\"]=None\n",
    "                else:\n",
    "                    continue    \n",
    "                paperId = paper.get(\"paperId\")\n",
    "                paper_authors = paper[\"authors\"]\n",
    "\n",
    "                writers['paper'].writerow({\n",
    "                    \"paperId\": paperId,\n",
    "                    \"corpusId\": paper.get(\"corpusId\"),\n",
    "                    \"title\":  paper.get(\"title\").strip().replace(\"\\n\", \" \").replace(\"|\", \" \").replace('\"', \"\").replace(\"^\", \" \"),\n",
    "                    \"referenceAuthorId\": get_referencing_author_id(paper_authors),\n",
    "                    \"abstract\": paper.get(\"abstract\").strip().replace(\"\\n\", \" \").replace(\"|\", \" \").replace('\"', \"\").replace(\"^\", \" \"),\n",
    "                    \"url\": paper.get(\"url\"),\n",
    "                    \"year\": paper.get(\"year\"),\n",
    "                    \"publicationType\": paper.get(\"publicationType\"),\n",
    "                    \"publicationDate\": paper.get(\"publicationDate\"),\n",
    "                })\n",
    "\n",
    "                new_papers = set([paper['paperId'] for paper in paper['references']])\n",
    "                process_new_papers(processed_papers, to_be_processed_papers, processing_papers_id, new_papers)\n",
    "\n",
    "                for new_paper in new_papers:\n",
    "                    writers['paper_paper'].writerow({\n",
    "                        \"citingPaperId\": paperId,\n",
    "                        \"citedPaperId\": new_paper,\n",
    "                    })\n",
    "\n",
    "                for author in paper_authors:\n",
    "                    authorId = author.get(\"authorId\")\n",
    "                    writers['paper_author'].writerow({\n",
    "                        \"paperId\": paperId,\n",
    "                        \"authorId\": authorId\n",
    "                    })\n",
    "\n",
    "                    if authorId not in set_authors:\n",
    "                        writers['author'].writerow({\n",
    "                            \"authorId\": authorId,\n",
    "                            \"authorName\": author.get(\"name\")\n",
    "                        })\n",
    "\n",
    "                        set_authors.add(authorId)\n",
    "            \n",
    "                paper_keywords = paper.get(\"s2FieldsOfStudy\", [])\n",
    "                paper_keywords = set(map(lambda x: x['category'], paper_keywords))\n",
    "\n",
    "                for keyword in paper_keywords:\n",
    "                    writers[\"paper_keywords\"].writerow({\n",
    "                            \"paperId\": paperId,\n",
    "                            \"keyword\": keyword\n",
    "                        })\n",
    "                    \n",
    "                    if keyword not in set_keywords:\n",
    "                        writers[\"keywords\"].writerow({\n",
    "                            \"keyword\": keyword\n",
    "                        })\n",
    "\n",
    "                        set_keywords.add(keyword)\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>corpusId</th>\n",
       "      <th>title</th>\n",
       "      <th>referenceAuthorId</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>publicationType</th>\n",
       "      <th>publicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>948fd800ecdd3c99488dde36b41480ca1b8acce3</td>\n",
       "      <td>53214999</td>\n",
       "      <td>The PRIDE database and related tools and resou...</td>\n",
       "      <td>1.390052e+09</td>\n",
       "      <td>Abstract The PRoteomics IDEntifications (PRIDE...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/948fd800...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Conference</td>\n",
       "      <td>2018-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59c9f2036e673d8bc9713eed851d12c6c9fe53cb</td>\n",
       "      <td>9267632</td>\n",
       "      <td>A universal algorithm for sequential data comp...</td>\n",
       "      <td>1.457204e+08</td>\n",
       "      <td>A universal algorithm for sequential data comp...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/59c9f203...</td>\n",
       "      <td>1977</td>\n",
       "      <td>Conference</td>\n",
       "      <td>1977-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>422876e542daadefe3371091a65c5671185796e2</td>\n",
       "      <td>5131034</td>\n",
       "      <td>Attribute-based encryption for fine-grained ac...</td>\n",
       "      <td>1.707396e+06</td>\n",
       "      <td>As more sensitive data is shared and stored by...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/422876e5...</td>\n",
       "      <td>2006</td>\n",
       "      <td>Conference</td>\n",
       "      <td>2006-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29858b40a15704398aecdca6bd2820f2fcc99891</td>\n",
       "      <td>219636053</td>\n",
       "      <td>Training Generative Adversarial Networks with ...</td>\n",
       "      <td>2.976930e+06</td>\n",
       "      <td>Training generative adversarial networks (GAN)...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/29858b40...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Conference</td>\n",
       "      <td>2020-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f117c6f12d067bd66dad40996b3931c069daa2da</td>\n",
       "      <td>18293514</td>\n",
       "      <td>Business Intelligence and Analytics: From Big ...</td>\n",
       "      <td>4.766666e+07</td>\n",
       "      <td>Business intelligence and analytics (BI&amp;A) has...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f117c6f1...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Conference</td>\n",
       "      <td>2012-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>cfd538dd2998ede6599b45b27a4f7b72b4c99adf</td>\n",
       "      <td>207197892</td>\n",
       "      <td>Self-indexing inverted files for fast text ret...</td>\n",
       "      <td>1.444485e+08</td>\n",
       "      <td>Query-processing costs on large text databases...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/cfd538dd...</td>\n",
       "      <td>1996</td>\n",
       "      <td>Conference</td>\n",
       "      <td>1996-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>5f14a9595b0796ce6e5338f157b763326c1f632f</td>\n",
       "      <td>11757052</td>\n",
       "      <td>Tom-vs-Pete Classifiers and Identity-Preservin...</td>\n",
       "      <td>2.053403e+09</td>\n",
       "      <td>We propose a method of face verification that ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/5f14a959...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Conference</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>7f4a6d9806b1329706756634d082cb56348b44b7</td>\n",
       "      <td>16145112</td>\n",
       "      <td>Mosaics of scenes with moving objects</td>\n",
       "      <td>2.111092e+09</td>\n",
       "      <td>Image mosaics are useful for a variety of task...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/7f4a6d98...</td>\n",
       "      <td>1998</td>\n",
       "      <td>Conference</td>\n",
       "      <td>1998-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>ed2ffda943ddde6d06d3298bdcbe62633d4c20de</td>\n",
       "      <td>24862145</td>\n",
       "      <td>Recombinant immunotoxins specific for a mutant...</td>\n",
       "      <td>2.243822e+09</td>\n",
       "      <td>EGFRvIII is a mutant epidermal growth factor r...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/ed2ffda9...</td>\n",
       "      <td>1996</td>\n",
       "      <td>Conference</td>\n",
       "      <td>1996-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>d3ebc6dd173de57c8df1adad370c88485d6dc227</td>\n",
       "      <td>62422224</td>\n",
       "      <td>Pattern recognition with measurement space and...</td>\n",
       "      <td>1.710238e+06</td>\n",
       "      <td>Remote sensor imaging technology makes it poss...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/d3ebc6dd...</td>\n",
       "      <td>1969</td>\n",
       "      <td>Conference</td>\n",
       "      <td>1969-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1264 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paperId   corpusId  \\\n",
       "0     948fd800ecdd3c99488dde36b41480ca1b8acce3   53214999   \n",
       "1     59c9f2036e673d8bc9713eed851d12c6c9fe53cb    9267632   \n",
       "2     422876e542daadefe3371091a65c5671185796e2    5131034   \n",
       "3     29858b40a15704398aecdca6bd2820f2fcc99891  219636053   \n",
       "4     f117c6f12d067bd66dad40996b3931c069daa2da   18293514   \n",
       "...                                        ...        ...   \n",
       "1259  cfd538dd2998ede6599b45b27a4f7b72b4c99adf  207197892   \n",
       "1260  5f14a9595b0796ce6e5338f157b763326c1f632f   11757052   \n",
       "1261  7f4a6d9806b1329706756634d082cb56348b44b7   16145112   \n",
       "1262  ed2ffda943ddde6d06d3298bdcbe62633d4c20de   24862145   \n",
       "1263  d3ebc6dd173de57c8df1adad370c88485d6dc227   62422224   \n",
       "\n",
       "                                                  title  referenceAuthorId  \\\n",
       "0     The PRIDE database and related tools and resou...       1.390052e+09   \n",
       "1     A universal algorithm for sequential data comp...       1.457204e+08   \n",
       "2     Attribute-based encryption for fine-grained ac...       1.707396e+06   \n",
       "3     Training Generative Adversarial Networks with ...       2.976930e+06   \n",
       "4     Business Intelligence and Analytics: From Big ...       4.766666e+07   \n",
       "...                                                 ...                ...   \n",
       "1259  Self-indexing inverted files for fast text ret...       1.444485e+08   \n",
       "1260  Tom-vs-Pete Classifiers and Identity-Preservin...       2.053403e+09   \n",
       "1261              Mosaics of scenes with moving objects       2.111092e+09   \n",
       "1262  Recombinant immunotoxins specific for a mutant...       2.243822e+09   \n",
       "1263  Pattern recognition with measurement space and...       1.710238e+06   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     Abstract The PRoteomics IDEntifications (PRIDE...   \n",
       "1     A universal algorithm for sequential data comp...   \n",
       "2     As more sensitive data is shared and stored by...   \n",
       "3     Training generative adversarial networks (GAN)...   \n",
       "4     Business intelligence and analytics (BI&A) has...   \n",
       "...                                                 ...   \n",
       "1259  Query-processing costs on large text databases...   \n",
       "1260  We propose a method of face verification that ...   \n",
       "1261  Image mosaics are useful for a variety of task...   \n",
       "1262  EGFRvIII is a mutant epidermal growth factor r...   \n",
       "1263  Remote sensor imaging technology makes it poss...   \n",
       "\n",
       "                                                    url  year publicationType  \\\n",
       "0     https://www.semanticscholar.org/paper/948fd800...  2018      Conference   \n",
       "1     https://www.semanticscholar.org/paper/59c9f203...  1977      Conference   \n",
       "2     https://www.semanticscholar.org/paper/422876e5...  2006      Conference   \n",
       "3     https://www.semanticscholar.org/paper/29858b40...  2020      Conference   \n",
       "4     https://www.semanticscholar.org/paper/f117c6f1...  2012      Conference   \n",
       "...                                                 ...   ...             ...   \n",
       "1259  https://www.semanticscholar.org/paper/cfd538dd...  1996      Conference   \n",
       "1260  https://www.semanticscholar.org/paper/5f14a959...  2012      Conference   \n",
       "1261  https://www.semanticscholar.org/paper/7f4a6d98...  1998      Conference   \n",
       "1262  https://www.semanticscholar.org/paper/ed2ffda9...  1996      Conference   \n",
       "1263  https://www.semanticscholar.org/paper/d3ebc6dd...  1969      Conference   \n",
       "\n",
       "     publicationDate  \n",
       "0         2018-11-05  \n",
       "1         1977-05-01  \n",
       "2         2006-10-30  \n",
       "3         2020-06-01  \n",
       "4         2012-12-01  \n",
       "...              ...  \n",
       "1259      1996-10-01  \n",
       "1260             NaN  \n",
       "1261      1998-06-23  \n",
       "1262      1996-12-10  \n",
       "1263      1969-04-01  \n",
       "\n",
       "[1264 rows x 9 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file=\"csv/citations.csv\"\n",
    "papers_file = \"csv/paper.csv\"  \n",
    "\n",
    "df=pd.read_csv(papers_file, delimiter='|')\n",
    "dic_cite=[]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2287a3930a7568a956aae5f3f037efe8fed675e7',\n",
       " 'ab9b7934d62c79c16e8792be580e22dc7aebc967',\n",
       " '948fd800ecdd3c99488dde36b41480ca1b8acce3',\n",
       " '114d9e30d388fa5b74797b864d092a0ee63e5b27',\n",
       " '44787913722b856c22c9c81ded1c735c24ad4de4',\n",
       " 'cc90910b6e31fe44cddc1e341f21eec0aaa5db44',\n",
       " 'a992c8fd24587f12d41f48df84b29d847634c0e4',\n",
       " '7e7343a5608fff1c68c5259db0c77b9193f1546d',\n",
       " '627be67feb084f1266cfc36e5aed3c3e7e6ce5f0',\n",
       " '8bb6cc4057c0f76e963f19918a79697acbd2bc41',\n",
       " 'fa02f9123abacd5ba13d41e937d99c077da8d3f6',\n",
       " '0e6ef2809bad0965b3df599b05be1e6d859d5543',\n",
       " '9f1b79d77201016a2579c013c5d490a12ab596b7',\n",
       " '6d8c9fcce8177d6f8d122d653c7d32d7624d6714',\n",
       " '67556c4f0cfdd1f09fff373768b03638f949be0d',\n",
       " 'e7c8aa2cb2223f17615c1b1ae3b33095466e95cc',\n",
       " '05e25b9797de9a544ca50e743aa2a15eb129ea72',\n",
       " '4e2f43dab69d690dc86422949e410ebf37f522d4',\n",
       " '6e00f7980c4efc55ba76efdccebc6411f054a7da',\n",
       " 'dcd99d49af33bd14e9e0750bcf854e7b306c808a',\n",
       " '82d02d8c697119a879756b5393c4aa5defeaa030']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['paperId'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified JSONL saved to csv/authors.csv\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.semanticscholar.org/graph/v1/author/batch\"\n",
    "output_file=\"csv/authors.csv\"\n",
    "papers_file = \"csv/papers.csv\" \n",
    "count=0  \n",
    "query_params = {\n",
    "    \"fields\": \"name,url,paperCount,hIndex\"#,papers\"\n",
    "}\n",
    "\n",
    "df=pd.read_csv(papers_file)\n",
    "ids=df[\"authorId\"].values.tolist()\n",
    "\n",
    "data = {\n",
    "    \"ids\": ids\n",
    "}\n",
    "api_key = os.environ.get('API_KEY')\n",
    "headers = {\"x-api-key\": api_key}\n",
    "\n",
    "# Send the API request\n",
    "response = requests.post(url, params=query_params, json=data, headers=headers).json()\n",
    "# Save the results to json file\n",
    "with open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile  :   \n",
    "    csv_writer_1 = csv.DictWriter(outfile, fieldnames=[\"sid\",\"authorId\", \"url\", \"name\", \"paperCount\", \"hIndex\"])\n",
    "\n",
    "    # Write the headers to the CSV files\n",
    "    csv_writer_1.writeheader()\n",
    "    for paper in response:\n",
    "        count+=1\n",
    "        try:  \n",
    "            paper_row = {\n",
    "                        \"sid\": count, # Add a new column with a surrogated ID, just in case\n",
    "                        \"authorId\": paper.get(\"authorId\"),\n",
    "                        \"url\": paper.get(\"url\"),\n",
    "                        \"name\": paper.get(\"name\"),\n",
    "                        \"paperCount\": paper.get(\"paperCount\"),\n",
    "                        \"hIndex\": paper.get(\"hIndex\")\n",
    "                        }\n",
    "            # Write the row to CSV 1\n",
    "            csv_writer_1.writerow(paper_row)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "print(f\"Modified JSONL saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
